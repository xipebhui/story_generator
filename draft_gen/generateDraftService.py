#!/usr/bin/env python3
"""
å‰ªæ˜ è‰ç¨¿ç”ŸæˆæœåŠ¡
ç»¼åˆéŸ³é¢‘ã€å¤šå›¾ç‰‡ã€è½¬åœºå’Œç‰¹æ•ˆçš„å®Œæ•´è‰ç¨¿ç”ŸæˆæœåŠ¡
"""

import os
import sys
import json
import shutil
import random
import argparse
import zipfile
from typing import List, Optional
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from pydub import AudioSegment
from models.draft_models import (
    Draft, Track, Segment, VideoMaterial, AudioMaterial, Materials,
    Timerange, Clip, Transition, VideoEffect
)
from models.draft_effects_library import (
    Transitions, VideoEffects, SpeedInfo, CanvasInfo, MaterialAnimationInfo
)
import uuid


def gen_upper_uuid():
    """ç”Ÿæˆå¤§å†™UUID"""
    return str(uuid.uuid4()).upper().replace('-', '')


class DraftGeneratorService:
    """å‰ªæ˜ è‰ç¨¿ç”ŸæˆæœåŠ¡"""

    def __init__(self):
        """åˆå§‹åŒ–æœåŠ¡"""
        self.supported_image_formats = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp']
        self.supported_audio_formats = ['.mp3', '.wav', '.m4a', '.aac', '.flac', '.ogg']

        # å¯ç”¨çš„è½¬åœºåˆ—è¡¨ï¼ˆç”¨äºéšæœºé€‰æ‹©ï¼‰
        self.available_transitions = [
            Transitions.PUSH_IN_II,
            Transitions.SLIDE_RIGHT
        ]

        # å¯ç”¨çš„ç‰¹æ•ˆåˆ—è¡¨ï¼ˆç”¨äºéšæœºé€‰æ‹©ï¼‰
        self.available_effects = [
            VideoEffects.SNOW
        ]

    def get_audio_duration_ms(self, audio_path: str) -> int:
        """è·å–éŸ³é¢‘æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰"""
        audio = AudioSegment.from_file(audio_path)
        return len(audio)

    def scan_images(self, images_dir: str) -> List[str]:
        """æ‰«æç›®å½•ä¸‹çš„æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶"""
        images = []
        for file_path in Path(images_dir).iterdir():
            if file_path.is_file() and file_path.suffix.lower() in self.supported_image_formats:
                images.append(str(file_path))

        # æŒ‰æ–‡ä»¶åæ’åº
        images.sort()
        return images

    def select_random_images(self, all_images: List[str], total_duration_ms: int, image_duration_ms: int) -> List[str]:
        """
        æ ¹æ®éŸ³é¢‘æ—¶é•¿å’Œå›¾ç‰‡æ˜¾ç¤ºæ—¶é•¿ï¼Œéšæœºé€‰æ‹©å¹¶æ’åˆ—å›¾ç‰‡

        Args:
            all_images: æ‰€æœ‰å¯ç”¨çš„å›¾ç‰‡è·¯å¾„
            total_duration_ms: æ€»æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
            image_duration_ms: æ¯å¼ å›¾ç‰‡æ˜¾ç¤ºæ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰

        Returns:
            é€‰ä¸­çš„å›¾ç‰‡è·¯å¾„åˆ—è¡¨ï¼ˆå¯èƒ½æœ‰é‡å¤ï¼‰
        """
        if not all_images:
            return []

        # è®¡ç®—éœ€è¦å¤šå°‘å¼ å›¾ç‰‡
        num_images_needed = total_duration_ms // image_duration_ms
        if total_duration_ms % image_duration_ms > 0:
            num_images_needed += 1

        selected_images = []

        # å¦‚æœå›¾ç‰‡æ•°é‡ä¸å¤Ÿï¼Œéœ€è¦é‡å¤ä½¿ç”¨
        if len(all_images) >= num_images_needed:
            # éšæœºé€‰æ‹©ä¸é‡å¤çš„å›¾ç‰‡
            selected_images = random.sample(all_images, num_images_needed)
        else:
            # éœ€è¦é‡å¤ä½¿ç”¨å›¾ç‰‡
            # å…ˆç”¨å®Œæ‰€æœ‰å›¾ç‰‡
            selected_images = all_images.copy()
            random.shuffle(selected_images)

            # è¡¥å……å‰©ä½™çš„
            remaining = num_images_needed - len(all_images)
            for _ in range(remaining):
                selected_images.append(random.choice(all_images))

        return selected_images

    def generate_draft(
            self,
            images_dir: str,
            audio_path: str,
            image_duration_seconds: float,
            video_title: str,
            output_dir: str,
            enable_transitions: bool = True,
            enable_effects: bool = True,
            random_seed: Optional[int] = None
    ) -> str:
        """
        ç”Ÿæˆå‰ªæ˜ è‰ç¨¿

        Args:
            images_dir: å›¾ç‰‡ç›®å½•è·¯å¾„
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            image_duration_seconds: æ¯å¼ å›¾ç‰‡æ˜¾ç¤ºæ—¶é•¿ï¼ˆç§’ï¼‰
            video_title: è§†é¢‘æ ‡é¢˜ï¼ˆç”¨ä½œè‰ç¨¿ç›®å½•åï¼‰
            output_dir: è¾“å‡ºç›®å½•è·¯å¾„
            enable_transitions: æ˜¯å¦å¯ç”¨è½¬åœº
            enable_effects: æ˜¯å¦å¯ç”¨ç‰¹æ•ˆ
            random_seed: éšæœºç§å­ï¼ˆç”¨äºå¤ç°ç»“æœï¼‰

        Returns:
            ç”Ÿæˆçš„è‰ç¨¿ç›®å½•è·¯å¾„
        """

        # è®¾ç½®éšæœºç§å­
        if random_seed is not None:
            random.seed(random_seed)

        print(f"\n{'=' * 60}")
        print(f"å¼€å§‹ç”Ÿæˆå‰ªæ˜ è‰ç¨¿")
        print(f"è§†é¢‘æ ‡é¢˜: {video_title}")
        print(f"{'=' * 60}\n")

        # 1. éªŒè¯è¾“å…¥
        if not os.path.exists(images_dir):
            raise ValueError(f"å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {images_dir}")
        if not os.path.exists(audio_path):
            raise ValueError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")

        # 2. æ‰«æå›¾ç‰‡
        print("æ‰«æå›¾ç‰‡æ–‡ä»¶...")
        all_images = self.scan_images(images_dir)
        if not all_images:
            raise ValueError(f"ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶: {images_dir}")
        print(f"æ‰¾åˆ° {len(all_images)} å¼ å›¾ç‰‡")

        # 3. è·å–éŸ³é¢‘æ—¶é•¿
        print("\nåˆ†æéŸ³é¢‘æ–‡ä»¶...")
        audio_duration_ms = self.get_audio_duration_ms(audio_path)
        audio_duration_us = audio_duration_ms * 1000  # è½¬æ¢ä¸ºå¾®ç§’
        print(f"éŸ³é¢‘æ—¶é•¿: {audio_duration_ms / 1000:.2f} ç§’")

        # 4. è®¡ç®—å›¾ç‰‡é…ç½®
        image_duration_ms = int(image_duration_seconds * 1000)
        image_duration_us = image_duration_ms * 1000  # è½¬æ¢ä¸ºå¾®ç§’

        # 5. é€‰æ‹©å›¾ç‰‡
        print(f"\né€‰æ‹©å›¾ç‰‡ï¼ˆæ¯å¼ æ˜¾ç¤º {image_duration_seconds} ç§’ï¼‰...")
        selected_images = self.select_random_images(all_images, audio_duration_ms, image_duration_ms)
        print(f"å°†ä½¿ç”¨ {len(selected_images)} å¼ å›¾ç‰‡")

        # 6. åˆ›å»ºè¾“å‡ºç›®å½•
        draft_dir = os.path.join(output_dir, video_title)
        materials_dir = os.path.join(draft_dir, "materials")
        os.makedirs(materials_dir, exist_ok=True)
        print(f"\nåˆ›å»ºè¾“å‡ºç›®å½•: {draft_dir}")

        # 7. å¤åˆ¶ç´ ææ–‡ä»¶
        print("\nå¤åˆ¶ç´ ææ–‡ä»¶...")

        # å¤åˆ¶éŸ³é¢‘
        audio_filename = f"audio_{os.path.basename(audio_path)}"
        audio_dest = os.path.join(materials_dir, audio_filename)
        shutil.copy(audio_path, audio_dest)
        audio_relative_path = f"##_draftpath_placeholder_0E685133-18CE-45ED-8CB8-2904A212EC80_##/materials/{audio_filename}"
        print(f"å¤åˆ¶éŸ³é¢‘: {os.path.basename(audio_path)}")

        # å¤åˆ¶å›¾ç‰‡
        image_relative_paths = []
        for i, image_path in enumerate(selected_images):
            ext = os.path.splitext(image_path)[1]
            image_filename = f"image_{i:03d}{ext}"
            image_dest = os.path.join(materials_dir, image_filename)
            shutil.copy(image_path, image_dest)
            relative_path = f"##_draftpath_placeholder_0E685133-18CE-45ED-8CB8-2904A212EC80_##/materials/{image_filename}"
            image_relative_paths.append(relative_path)
            if i < 10:  # åªæ˜¾ç¤ºå‰10ä¸ª
                print(f"å¤åˆ¶å›¾ç‰‡ {i + 1}: {os.path.basename(image_path)}")
        if len(selected_images) > 10:
            print(f"... å’Œå…¶ä»– {len(selected_images) - 10} å¼ å›¾ç‰‡")

        # 8. åˆ›å»ºè‰ç¨¿å¯¹è±¡
        print("\nåˆ›å»ºè‰ç¨¿å¯¹è±¡...")
        draft = self._create_draft_object(
            audio_relative_path,
            image_relative_paths,
            audio_duration_us,
            image_duration_us,
            enable_transitions,
            enable_effects
        )

        # 9. å¤åˆ¶å…ƒä¿¡æ¯æ–‡ä»¶
        print("\nå¤åˆ¶å…ƒä¿¡æ¯æ–‡ä»¶...")
        self._copy_meta_files(draft_dir)

        # 10. ä¿å­˜è‰ç¨¿
        print("\nä¿å­˜è‰ç¨¿æ–‡ä»¶...")
        self._save_draft(draft, draft_dir)

        # 11. åˆ›å»º ZIP åŒ…
        print("\nåˆ›å»º ZIP åŒ…...")
        zip_path = self._create_zip_package(draft_dir)

        print(f"\n{'=' * 60}")
        print(f"âœ… ç”Ÿæˆå®Œæˆ!")
        print(f"è‰ç¨¿ç›®å½•: {draft_dir}")
        print(f"ZIP åŒ…: {zip_path}")
        print(f"æ€»æ—¶é•¿: {audio_duration_ms / 1000:.2f} ç§’")
        print(f"å›¾ç‰‡æ•°é‡: {len(selected_images)}")
        if enable_transitions:
            print(f"åŒ…å«è½¬åœº: {len(selected_images) - 1} ä¸ª")
        if enable_effects:
            print(f"åŒ…å«ç‰¹æ•ˆ: å·²æ·»åŠ éšæœºç‰¹æ•ˆ")
        print(f"ç”»å¸ƒæ¯”ä¾‹: 16:9 (1920x1080)")
        print(f"\nğŸ“Œ å¯ä»¥å°†è‰ç¨¿ ZIP åŒ…å¯¼å…¥å‰ªæ˜ ä½¿ç”¨")
        print(f"{'=' * 60}\n")

        return draft_dir

    def _create_draft_object(
            self,
            audio_relative_path: str,
            image_relative_paths: List[str],
            audio_duration_us: int,
            image_duration_us: int,
            enable_transitions: bool,
            enable_effects: bool
    ) -> Draft:
        """åˆ›å»ºè‰ç¨¿å¯¹è±¡ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰"""

        materials = Materials()
        draft_id = gen_upper_uuid()

        # 1. åˆ›å»ºéŸ³é¢‘ç´ æ
        audio_material = AudioMaterial(
            id=gen_upper_uuid(),
            path=audio_relative_path,
            duration=audio_duration_us,
            material_name="èƒŒæ™¯éŸ³ä¹"
        )
        materials.audios = [audio_material.to_dict()]

        # 2. åˆ›å»ºè§†é¢‘ç´ æï¼ˆå›¾ç‰‡ï¼‰
        video_materials = []
        for i, image_path in enumerate(image_relative_paths):
            video_material = VideoMaterial(
                id=gen_upper_uuid(),
                path=image_path,
                duration=image_duration_us,
                width=1920,
                height=1080,
                material_name=f"å›¾ç‰‡{i + 1}"
            )
            video_materials.append(video_material)
            materials.videos.append(video_material.to_dict())

        # 3. åˆ›å»ºè½¬åœºï¼ˆå¦‚æœå¯ç”¨ï¼‰
        transitions = []
        if enable_transitions and len(video_materials) > 1:
            for i in range(len(video_materials) - 1):
                # éšæœºé€‰æ‹©ä¸€ä¸ªè½¬åœº
                transition_info = random.choice(self.available_transitions)
                transition = Transition(
                    id=gen_upper_uuid(),
                    effect_id=transition_info.effect_id,
                    name=transition_info.name,
                    duration=466666,  # çº¦0.47ç§’
                    is_overlap=transition_info.is_overlap,
                    category_id=transition_info.category_id,
                    category_name=transition_info.category_name,
                    path=transition_info.get_path(),
                    resource_id=transition_info.resource_id
                )
                transitions.append(transition)
                materials.transitions.append(transition.to_dict())

        # 4. åˆ›å»ºç‰¹æ•ˆï¼ˆå¦‚æœå¯ç”¨ï¼‰
        video_effect = None
        if enable_effects:
            # éšæœºé€‰æ‹©ä¸€ä¸ªç‰¹æ•ˆ
            effect_info = random.choice(self.available_effects)
            video_effect = VideoEffect(
                id=gen_upper_uuid(),
                effect_id=effect_info.effect_id,
                name=effect_info.name,
                category_id=effect_info.category_id,
                category_name=effect_info.category_name,
                path=effect_info.get_path(),
                resource_id=effect_info.resource_id,
                adjust_params=effect_info.adjust_params,
                value=effect_info.default_value,
                render_index=0,
                track_render_index=0
            )
            materials.video_effects.append(video_effect.to_dict())

        # 5. åˆ›å»ºè¾…åŠ©ç´ æ
        for i in range(len(video_materials)):
            materials.speeds.append(SpeedInfo.create_speed_dict())
            materials.canvases.append(CanvasInfo.create_canvas_dict())
            materials.sound_channel_mappings.append({
                "id": gen_upper_uuid(),
                "audio_channel_mapping": 0,
                "is_config_open": False,
                "type": ""
            })
            materials.vocal_separations.append({
                "id": gen_upper_uuid(),
                "choice": 0,
                "production_path": "",
                "time_range": None,
                "type": "vocal_separation"
            })

        # æ·»åŠ ç´ æåŠ¨ç”»
        for _ in range(len(transitions)):
            materials.material_animations.append(MaterialAnimationInfo.create_animation_dict())

        # 6. åˆ›å»ºè§†é¢‘è½¨é“
        video_track = Track(
            id=gen_upper_uuid(),
            type="video",
            segments=[],
            attribute=1
        )

        # åˆ›å»ºè§†é¢‘ç‰‡æ®µ
        current_time = 0
        for i, video_material in enumerate(video_materials):
            # ç¡®ä¿ä¸è¶…è¿‡éŸ³é¢‘æ—¶é•¿
            if current_time >= audio_duration_us:
                break

            # è®¡ç®—ç‰‡æ®µæ—¶é•¿
            segment_duration = min(image_duration_us, audio_duration_us - current_time)

            # åˆ›å»ºé¢å¤–å¼•ç”¨
            extra_refs = []
            if i < len(materials.speeds):
                extra_refs.append(materials.speeds[i]["id"])
            if enable_transitions and i < len(transitions):
                extra_refs.append(transitions[i].id)
            if i < len(materials.canvases):
                extra_refs.append(materials.canvases[i]["id"])
            if i < len(materials.material_animations):
                extra_refs.append(materials.material_animations[i]["id"])
            if i < len(materials.sound_channel_mappings):
                extra_refs.append(materials.sound_channel_mappings[i]["id"])
            if i < len(materials.vocal_separations):
                extra_refs.append(materials.vocal_separations[i]["id"])

            # åˆ›å»ºç‰‡æ®µ
            video_segment = Segment(
                id=gen_upper_uuid(),
                material_id=video_material.id,
                target=Timerange(start=current_time, duration=segment_duration),
                source=Timerange(start=0, duration=segment_duration),
                speed=1.0,
                volume=0.0,
                clip=Clip(
                    alpha=1.0,
                    rotation=0.0,
                    scale={"x": 1.0, "y": 1.0},
                    transform={"x": 0.0, "y": 0.0}
                ),
                extra_refs=extra_refs
            )
            video_track.segments.append(video_segment)
            current_time += segment_duration

        # 7. åˆ›å»ºéŸ³é¢‘è½¨é“
        audio_track = Track(
            id=gen_upper_uuid(),
            type="audio",
            segments=[],
            attribute=0
        )

        audio_segment = Segment(
            id=gen_upper_uuid(),
            material_id=audio_material.id,
            target=Timerange(start=0, duration=audio_duration_us),
            source=Timerange(start=0, duration=audio_duration_us),
            speed=1.0,
            volume=1.0,
            clip=None,
            extra_refs=[
                materials.speeds[0]["id"] if materials.speeds else gen_upper_uuid(),
                materials.sound_channel_mappings[0]["id"] if materials.sound_channel_mappings else gen_upper_uuid(),
                materials.vocal_separations[0]["id"] if materials.vocal_separations else gen_upper_uuid()
            ]
        )
        audio_track.segments.append(audio_segment)

        # 8. åˆ›å»ºç‰¹æ•ˆè½¨é“ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        tracks = [video_track, audio_track]
        if enable_effects and video_effect:
            effect_track = Track(
                id=gen_upper_uuid(),
                type="effect",
                segments=[],
                attribute=0
            )

            effect_segment = Segment(
                id=gen_upper_uuid(),
                material_id=video_effect.id,
                target=Timerange(start=0, duration=audio_duration_us),
                source=Timerange(start=0, duration=0),
                speed=1.0,
                volume=1.0,
                clip=None
            )
            effect_track.segments.append(effect_segment)
            tracks.append(effect_track)

        # 9. åˆ›å»ºè‰ç¨¿
        draft = Draft(
            id=draft_id,
            duration=audio_duration_us,
            canvas_config={
                "height": 1080,
                "width": 1920,
                "ratio": "16:9"
            },
            materials=materials,
            tracks=tracks
        )

        return draft

    def _copy_meta_files(self, draft_dir: str):
        """å¤åˆ¶å…ƒä¿¡æ¯æ–‡ä»¶ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰"""
        # è·å–é…ç½®æ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼ˆä¸å½“å‰è„šæœ¬åŒç›®å½•ï¼‰
        config_dir = os.path.dirname(__file__)
        
        # å¤åˆ¶ draft_meta_info.json
        meta_info_src = os.path.join(config_dir, "draft_meta_info.json")
        meta_info_dst = os.path.join(draft_dir, "draft_meta_info.json")
        if os.path.exists(meta_info_src):
            shutil.copy(meta_info_src, meta_info_dst)
            print("å¤åˆ¶å…ƒä¿¡æ¯: draft_meta_info.json")
        else:
            print(f"è­¦å‘Šï¼šæ‰¾ä¸åˆ°å…ƒä¿¡æ¯æ–‡ä»¶: {meta_info_src}")
            # å¦‚æœæ‰¾ä¸åˆ°æ–‡ä»¶ï¼Œåˆ›å»ºä¸€ä¸ªåŸºç¡€çš„
            meta_info = {
                "draft_materials": [],
                "draft_id": gen_upper_uuid(),
                "draft_name": os.path.basename(draft_dir)
            }
            with open(meta_info_dst, 'w', encoding='utf-8') as f:
                json.dump(meta_info, f, indent=4, ensure_ascii=False)
            print("åˆ›å»ºåŸºç¡€å…ƒä¿¡æ¯: draft_meta_info.json")

        # å¤åˆ¶ draft_settings
        settings_src = os.path.join(config_dir, "draft_settings")
        settings_dst = os.path.join(draft_dir, "draft_settings")
        if os.path.exists(settings_src):
            shutil.copy(settings_src, settings_dst)
            print("å¤åˆ¶è®¾ç½®æ–‡ä»¶: draft_settings")
        else:
            print(f"è­¦å‘Šï¼šæ‰¾ä¸åˆ°è®¾ç½®æ–‡ä»¶: {settings_src}")
            # å¦‚æœæ‰¾ä¸åˆ°æ–‡ä»¶ï¼Œåˆ›å»ºä¸€ä¸ªåŸºç¡€çš„
            settings_content = "[General]\n"
            with open(settings_dst, 'w', encoding='utf-8') as f:
                f.write(settings_content)
            print("åˆ›å»ºåŸºç¡€è®¾ç½®æ–‡ä»¶: draft_settings")

    def _create_zip_package(self, draft_dir: str) -> str:
        """åˆ›å»º ZIP åŒ…ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰"""
        zip_path = f"{draft_dir}.zip"
        
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            # éå†è‰ç¨¿ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
            for root, dirs, files in os.walk(draft_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    # è®¡ç®—åœ¨ ZIP ä¸­çš„ç›¸å¯¹è·¯å¾„ï¼Œä¸åŒ…å«é¡¶å±‚ç›®å½•å
                    arcname = os.path.relpath(file_path, draft_dir)
                    zipf.write(file_path, arcname)
                    
        # è·å– ZIP æ–‡ä»¶å¤§å°
        zip_size = os.path.getsize(zip_path) / (1024 * 1024)  # è½¬æ¢ä¸º MB
        print(f"ZIP åŒ…åˆ›å»ºå®Œæˆ: {os.path.basename(zip_path)} ({zip_size:.2f} MB)")
        
        return zip_path

    def _save_draft(self, draft: Draft, draft_dir: str):
        """ä¿å­˜è‰ç¨¿ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰"""
        draft_content_path = os.path.join(draft_dir, "draft_content.json")
        draft_dict = draft.to_dict()

        # ç¡®ä¿æ‰€æœ‰è½¨é“çš„segmentæœ‰æ­£ç¡®çš„å­—æ®µ
        for track in draft_dict.get("tracks", []):
            for segment in track.get("segments", []):
                if track["type"] == "video":
                    segment.update({
                        "enable_adjust": True,
                        "enable_color_correct_adjust": False,
                        "enable_color_curves": True,
                        "enable_color_match_adjust": False,
                        "enable_color_wheels": True,
                        "enable_lut": True,
                        "enable_smart_color_adjust": False,
                        "caption_info": None,
                        "cartoon": False,
                        "group_id": "",
                        "hdr_settings": None,
                        "intensifies_audio": False,
                        "is_tone_modify": False,
                        "last_nonzero_volume": 1.0,
                        "render_index": 0,
                        "responsive_layout": {
                            "enable": False,
                            "horizontal_pos_layout": 0,
                            "size_layout": 0,
                            "target_follow": "",
                            "vertical_pos_layout": 0
                        },
                        "track_render_index": 0,
                        "uniform_scale": {
                            "on": True,
                            "value": 1.0
                        }
                    })
                elif track["type"] == "audio":
                    if "clip" not in segment:
                        segment["clip"] = None
                    segment.update({
                        "enable_adjust": False,
                        "enable_color_correct_adjust": False,
                        "enable_color_curves": True,
                        "enable_color_match_adjust": False,
                        "enable_color_wheels": True,
                        "enable_lut": False,
                        "enable_smart_color_adjust": False,
                        "caption_info": None,
                        "cartoon": False,
                        "group_id": "",
                        "hdr_settings": None,
                        "intensifies_audio": False,
                        "is_tone_modify": False,
                        "last_nonzero_volume": 1.0,
                        "render_index": 0,
                        "responsive_layout": {
                            "enable": False,
                            "horizontal_pos_layout": 0,
                            "size_layout": 0,
                            "target_follow": "",
                            "vertical_pos_layout": 0
                        },
                        "track_render_index": 0,
                        "uniform_scale": None
                    })
                elif track["type"] == "effect":
                    segment["source_timerange"] = None
                    segment.update({
                        "render_index": 11000,
                        "track_render_index": 1,
                        "caption_info": None,
                        "cartoon": False,
                        "enable_adjust": False,
                        "enable_color_correct_adjust": False,
                        "enable_color_curves": True,
                        "enable_color_match_adjust": False,
                        "enable_color_wheels": True,
                        "enable_lut": False,
                        "enable_smart_color_adjust": False,
                        "group_id": "",
                        "hdr_settings": None,
                        "intensifies_audio": False,
                        "is_tone_modify": False,
                        "last_nonzero_volume": 1.0,
                        "responsive_layout": {
                            "enable": False,
                            "horizontal_pos_layout": 0,
                            "size_layout": 0,
                            "target_follow": "",
                            "vertical_pos_layout": 0
                        },
                        "uniform_scale": None
                    })

        with open(draft_content_path, 'w', encoding='utf-8') as f:
            json.dump(draft_dict, f, indent=4, ensure_ascii=False)
        print("ä¿å­˜è‰ç¨¿: draft_content.json")


def generate_draft_from_story(cid: str, vid: str, 
                             image_duration_seconds: float = 3.0,
                             enable_transitions: bool = True,
                             enable_effects: bool = True,
                             random_seed: Optional[int] = 42):
    """
    æ ¹æ®æ•…äº‹IDç”Ÿæˆå‰ªæ˜ è‰ç¨¿
    
    Args:
        cid: Creator ID
        vid: Voice ID
        image_duration_seconds: æ¯å¼ å›¾ç‰‡æ˜¾ç¤ºæ—¶é•¿ï¼ˆç§’ï¼‰
        enable_transitions: æ˜¯å¦å¯ç”¨è½¬åœº
        enable_effects: æ˜¯å¦å¯ç”¨ç‰¹æ•ˆ
        random_seed: éšæœºç§å­
    
    Returns:
        ç”Ÿæˆçš„è‰ç¨¿ç›®å½•è·¯å¾„
    """
    
    # æ„å»ºè·¯å¾„
    audio_path = f"./output/{cid}_{vid}_story.mp3"
    images_dir = "./output/images"
    video_title = f"{cid}_{vid}_story"
    output_dir = "./output/drafts"
    
    # éªŒè¯æ–‡ä»¶å­˜åœ¨
    if not os.path.exists(audio_path):
        raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
    
    if not os.path.exists(images_dir):
        raise FileNotFoundError(f"å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {images_dir}")
    
    # åˆ›å»ºæœåŠ¡å®ä¾‹
    service = DraftGeneratorService()
    
    try:
        # ç”Ÿæˆè‰ç¨¿
        draft_dir = service.generate_draft(
            images_dir=images_dir,
            audio_path=audio_path,
            image_duration_seconds=image_duration_seconds,
            video_title=video_title,
            output_dir=output_dir,
            enable_transitions=enable_transitions,
            enable_effects=enable_effects,
            random_seed=random_seed
        )
        
        return draft_dir
        
    except Exception as e:
        print(f"\nâŒ ç”Ÿæˆå¤±è´¥: {str(e)}")
        raise


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    
    # åˆ›å»ºå‚æ•°è§£æå™¨
    parser = argparse.ArgumentParser(description='ç”Ÿæˆå‰ªæ˜ è‰ç¨¿')
    parser.add_argument('--cid', type=str, required=True, help='Creator ID')
    parser.add_argument('--vid', type=str, required=True, help='Voice ID')
    parser.add_argument('--duration', type=float, default=3.0, 
                       help='æ¯å¼ å›¾ç‰‡æ˜¾ç¤ºæ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤3ç§’')
    parser.add_argument('--no-transitions', action='store_true',
                       help='ç¦ç”¨è½¬åœºæ•ˆæœ')
    parser.add_argument('--no-effects', action='store_true',
                       help='ç¦ç”¨è§†é¢‘ç‰¹æ•ˆ')
    parser.add_argument('--seed', type=int, default=42,
                       help='éšæœºç§å­ï¼Œç”¨äºå¤ç°ç»“æœ')
    
    # è§£æå‚æ•°
    args = parser.parse_args()
    
    print(f"\n{'=' * 60}")
    print(f"å‰ªæ˜ è‰ç¨¿ç”Ÿæˆå·¥å…·")
    print(f"{'=' * 60}")
    print(f"Creator ID: {args.cid}")
    print(f"Voice ID: {args.vid}")
    print(f"å›¾ç‰‡æ˜¾ç¤ºæ—¶é•¿: {args.duration} ç§’")
    print(f"è½¬åœºæ•ˆæœ: {'å¯ç”¨' if not args.no_transitions else 'ç¦ç”¨'}")
    print(f"è§†é¢‘ç‰¹æ•ˆ: {'å¯ç”¨' if not args.no_effects else 'ç¦ç”¨'}")
    print(f"{'=' * 60}\n")
    
    try:
        # ç”Ÿæˆè‰ç¨¿
        draft_dir = generate_draft_from_story(
            cid=args.cid,
            vid=args.vid,
            image_duration_seconds=args.duration,
            enable_transitions=not args.no_transitions,
            enable_effects=not args.no_effects,
            random_seed=args.seed
        )
        
        print(f"\nâœ¨ è‰ç¨¿å·²ç”Ÿæˆåˆ°: {draft_dir}")
        print("\nä¸‹ä¸€æ­¥æ“ä½œï¼š")
        print("1. æ‰“å¼€å‰ªæ˜ ä¸“ä¸šç‰ˆ")
        print("2. é€‰æ‹©'å¯¼å…¥è‰ç¨¿'")
        print("3. é€‰æ‹©ç”Ÿæˆçš„è‰ç¨¿æ–‡ä»¶å¤¹")
        print("4. å¼€å§‹ç¼–è¾‘ä½ çš„è§†é¢‘ï¼")
        
    except FileNotFoundError as e:
        print(f"\nâŒ æ–‡ä»¶æœªæ‰¾åˆ°: {str(e)}")
        print("\nè¯·ç¡®ä¿å·²ç»å®Œæˆä»¥ä¸‹æ­¥éª¤ï¼š")
        print("1. ç”Ÿæˆæ•…äº‹éŸ³é¢‘: python voice_gen/tts_client.py --cid <cid> --vid <vid> --gender <0|1>")
        print("2. ç”Ÿæˆå›¾ç‰‡: python image_generator.py")
        
    except Exception as e:
        print(f"\nâŒ ç”Ÿæˆå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()