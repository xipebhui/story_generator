#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
YouTube Story Creator V2
ä½¿ç”¨æ–°çš„ä¸Šä¸‹æ–‡ç®¡ç†ç­–ç•¥å’Œ30ä¸ªç‰‡æ®µçš„äºŒçº§æ¡†æ¶
ä¸“æ³¨äº30000å­—é•¿æ•…äº‹çš„ç”Ÿæˆ
"""

import os
import sys
import json
import logging
import time
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
project_root = Path(__file__).parent
print(f"--- project path = {project_root}")
sys.path.insert(0, str(project_root))

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from youtube_client import YouTubeAPIClient
from gemini_client import GeminiClient
from text_processor import TextProcessor
from image_prompt_generator import ImagePromptGenerator

# é…ç½®æ—¥å¿—
# æ¸…é™¤é»˜è®¤é…ç½®
for handler in logging.root.handlers[:]:
    logging.root.removeHandler(handler)

# è®¾ç½®æ ¹æ—¥å¿—çº§åˆ«
logging.root.setLevel(logging.DEBUG)

# åˆ›å»ºæ ¼å¼å™¨
formatter = logging.Formatter(
    '%(asctime)s [%(levelname)s] %(filename)s:%(lineno)d - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

# æ§åˆ¶å°å¤„ç†å™¨ - åªæ˜¾ç¤ºINFOåŠä»¥ä¸Šçº§åˆ«
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_handler.setFormatter(formatter)

# ä¸»æ—¥å¿—æ–‡ä»¶ - è®°å½•INFOåŠä»¥ä¸Šçº§åˆ«
file_handler = logging.FileHandler('story_creator_v2.log', encoding='utf-8', mode='a')
file_handler.setLevel(logging.INFO)
file_handler.setFormatter(formatter)

# è°ƒè¯•æ—¥å¿—æ–‡ä»¶ - è®°å½•æ‰€æœ‰çº§åˆ«ï¼ˆåŒ…æ‹¬DEBUGï¼‰
debug_handler = logging.FileHandler('story_creator_v2_debug.log', encoding='utf-8', mode='a')
debug_handler.setLevel(logging.DEBUG)
debug_handler.setFormatter(formatter)

# æ·»åŠ å¤„ç†å™¨åˆ°æ ¹æ—¥å¿—å™¨
logging.root.addHandler(console_handler)
logging.root.addHandler(file_handler)
logging.root.addHandler(debug_handler)

logger = logging.getLogger(__name__)


class ContextManager:
    """ç®¡ç†Gemini APIçš„å¯¹è¯å†å²"""
    
    def __init__(self):
        self.history = []
    
    def add_global_context(self, story_dna: str, framework: str):
        """
        æ·»åŠ å…¨å±€ä¸Šä¸‹æ–‡ï¼ˆæœ€é«˜æŒ‡ç¤ºï¼‰
        
        Args:
            story_dna: æ•…äº‹DNA
            framework: å®Œæ•´çš„30ä¸ªç‰‡æ®µæ¡†æ¶
        """
        # ç”¨æˆ·æä¾›æœ€é«˜æŒ‡ç¤º
        global_context = f"""
{TextProcessor.SECTION_DIVIDER}
æœ€é«˜æŒ‡ç¤º - å®Œæ•´æ¡†æ¶ï¼ˆ30ä¸ªç‰‡æ®µï¼‰
{TextProcessor.SECTION_DIVIDER}
{framework}
"""
        
        self.history.append({
            "role": "user",
            "parts": [{"text": global_context}]
        })
        
        # æ¨¡å‹ç¡®è®¤ç†è§£
        self.history.append({
            "role": "model",
            "parts": [{"text": "æˆ‘å·²ç†è§£æœ€é«˜æŒ‡ç¤ºï¼ŒåŒ…æ‹¬æ•…äº‹DNAå’Œ30ä¸ªç‰‡æ®µçš„å®Œæ•´æ¡†æ¶ã€‚æˆ‘å°†ä¸¥æ ¼æŒ‰ç…§è¿™ä¸ªæ¡†æ¶ç”Ÿæˆæ¯ä¸ªç‰‡æ®µã€‚"}]
        })
    
    def add_segment_request(self, segment_input: str) -> None:
        """
        æ·»åŠ ç‰‡æ®µç”Ÿæˆè¯·æ±‚
        
        Args:
            segment_input: ç‰‡æ®µç”Ÿæˆçš„è¾“å…¥æ–‡æœ¬
        """
        self.history.append({
            "role": "user",
            "parts": [{"text": segment_input}]
        })
    
    def add_segment_response(self, segment_text: str) -> None:
        """
        æ·»åŠ ç‰‡æ®µç”Ÿæˆå“åº”
        
        Args:
            segment_text: ç”Ÿæˆçš„ç‰‡æ®µæ–‡æœ¬
        """
        self.history.append({
            "role": "model",
            "parts": [{"text": segment_text}]
        })
    
    def get_history(self) -> List[Dict]:
        """è·å–å®Œæ•´çš„å¯¹è¯å†å²"""
        return self.history.copy()


class YouTubeStoryCreatorV2:
    """æ–°ç‰ˆYouTubeæ•…äº‹åˆ›ä½œå™¨ - ä¸“æ³¨äº30000å­—é•¿æ•…äº‹"""
    
    def __init__(self, video_id: str, creator_name: str, target_length: int = 30000, num_segments: int = 9):
        """
        åˆå§‹åŒ–
        
        Args:
            video_id: YouTubeè§†é¢‘ID
            creator_name: åˆ›ä½œè€…åç§°
            target_length: ç›®æ ‡æ•…äº‹é•¿åº¦ï¼ˆé»˜è®¤30000å­—ï¼‰
            num_segments: ç‰‡æ®µæ•°é‡ï¼ˆé»˜è®¤9ä¸ªï¼Œå¯¹åº”9æ­¥ç»“æ„ï¼‰
        """
        self.video_id = video_id
        self.creator_name = creator_name
        self.target_length = target_length
        self.num_segments = num_segments  # é»˜è®¤9ä¸ªç‰‡æ®µ
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = Path("story_result") / creator_name / video_id
        self.raw_dir = self.output_dir / "raw"
        self.processing_dir = self.output_dir / "processing"
        self.segments_dir = self.output_dir / "segments"
        self.final_dir = self.output_dir / "final"
        
        for dir_path in [self.raw_dir, self.processing_dir, self.segments_dir, self.final_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        self._init_clients()
        
        # åŠ è½½æç¤ºè¯
        self._load_prompts()
        
        # æ–‡æœ¬å¤„ç†å™¨
        self.text_processor = TextProcessor()
        
        logger.info(f"âœ… åˆå§‹åŒ–å®Œæˆ - è§†é¢‘ID: {video_id}, åˆ›ä½œè€…: {creator_name}")
        logger.info(f"ğŸ“Š ç›®æ ‡é•¿åº¦: {target_length}å­—, ç‰‡æ®µæ•°: {self.num_segments}")
    
    def _init_clients(self):
        """åˆå§‹åŒ–APIå®¢æˆ·ç«¯"""
        # YouTube APIå¯†é’¥
        youtube_api_key = os.getenv("YOUTUBE_API_KEY", "AIzaSyCdbljoACNX1Ov3GsU6KRrnwWnCHAyyjVQ")
        
        # Gemini APIå¯†é’¥ï¼ˆä¼˜å…ˆä½¿ç”¨NewAPIï¼‰
        gemini_api_key = "sk-oFdSWMX8z3cAYYCrGYCcwAupxMdiErcOKBsfi5k0QdRxELCu"
        if not gemini_api_key:
            gemini_api_key = os.getenv("GEMINI_API_KEY", "your_gemini_api_key")
            logger.warning("âš ï¸ ä½¿ç”¨é»˜è®¤Gemini APIå¯†é’¥ï¼Œå»ºè®®è®¾ç½®NEWAPI_API_KEYç¯å¢ƒå˜é‡")
        
        self.youtube_client = YouTubeAPIClient()
        self.gemini_client = GeminiClient(api_key=gemini_api_key)
        
        logger.info("âœ… å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")
    
    def _load_prompts(self):
        """åŠ è½½æ‰€æœ‰æç¤ºè¯æ–‡ä»¶"""
        self.prompts = {}
        prompt_files = {
            "dna_extractor": "dna_extractor.md",
            "framework_generator": "framework_generate.md",
            "segment_generator": "segment_generator.md",
            "final_polisher": "final_polish.md"
        }
        
        prompts_dir = project_root / "prompts"
        for key, filename in prompt_files.items():
            file_path = prompts_dir / filename
            if file_path.exists():
                with open(file_path, 'r', encoding='utf-8') as f:
                    self.prompts[key] = f.read()
                logger.info(f"âœ… åŠ è½½æç¤ºè¯: {filename}")
            else:
                logger.error(f"âŒ æç¤ºè¯æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                raise FileNotFoundError(f"Missing prompt file: {file_path}")
    
    def fetch_youtube_data(self) -> Dict[str, Any]:
        """
        è·å–YouTubeè§†é¢‘æ•°æ®
        æ¯ä¸ªç»„ä»¶ï¼ˆè§†é¢‘è¯¦æƒ…ã€è¯„è®ºã€å­—å¹•ï¼‰éƒ½ç‹¬ç«‹æ£€æŸ¥ç¼“å­˜
        
        Returns:
            åŒ…å«è§†é¢‘ä¿¡æ¯ã€è¯„è®ºã€å­—å¹•çš„å­—å…¸
        """
        logger.info(f"ğŸ” å¼€å§‹è·å–YouTubeæ•°æ®: {self.video_id}")
        data = {}
        import json
        
        # å®šä¹‰ç¼“å­˜æ–‡ä»¶è·¯å¾„
        video_info_file = self.raw_dir / "video_info.json"
        comments_file = self.raw_dir / "comments.json" 
        subtitle_file = self.raw_dir / "subtitle.txt"
        
        # 1. è·å–æˆ–åŠ è½½è§†é¢‘è¯¦æƒ…
        if video_info_file.exists():
            logger.info("ğŸ“‚ å‘ç°è§†é¢‘è¯¦æƒ…ç¼“å­˜ï¼Œä»æ–‡ä»¶åŠ è½½...")
            try:
                with open(video_info_file, 'r', encoding='utf-8') as f:
                    data['video_info'] = json.load(f)
                logger.info(f"âœ… è§†é¢‘æ ‡é¢˜: {data['video_info']['title']}")
            except Exception as e:
                logger.warning(f"âš ï¸ åŠ è½½è§†é¢‘è¯¦æƒ…å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                data['video_info'] = None
        else:
            data['video_info'] = None
            
        if not data.get('video_info'):
            logger.info("ğŸ“Š ä»YouTubeè·å–è§†é¢‘è¯¦æƒ…...")
            try:
                video_details = self.youtube_client.get_video_details([self.video_id])
                if video_details and video_details.get('items'):
                    video_info = video_details['items'][0]
                    data['video_info'] = {
                        'title': video_info['snippet']['title'],
                        'description': video_info['snippet']['description'],
                        'channel_title': video_info['snippet']['channelTitle'],
                        'thumbnail': video_info['snippet']['thumbnails'].get('maxres', 
                                    video_info['snippet']['thumbnails'].get('high', {})).get('url', '')
                    }
                    # ä¿å­˜è§†é¢‘è¯¦æƒ…
                    with open(video_info_file, 'w', encoding='utf-8') as f:
                        json.dump(data['video_info'], f, ensure_ascii=False, indent=2)
                    logger.info(f"âœ… è§†é¢‘æ ‡é¢˜: {data['video_info']['title']}")
                    logger.info(f"ğŸ’¾ è§†é¢‘è¯¦æƒ…å·²ç¼“å­˜åˆ°: {video_info_file}")
            except Exception as e:
                logger.error(f"âŒ è·å–è§†é¢‘è¯¦æƒ…å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                return None
        
        # 2. è·å–æˆ–åŠ è½½è¯„è®º
        if comments_file.exists():
            logger.info("ğŸ“‚ å‘ç°è¯„è®ºç¼“å­˜ï¼Œä»æ–‡ä»¶åŠ è½½...")
            try:
                with open(comments_file, 'r', encoding='utf-8') as f:
                    data['comments'] = json.load(f)
                logger.info(f"âœ… åŠ è½½äº† {len(data['comments'])} æ¡çƒ­é—¨è¯„è®º")
            except Exception as e:
                logger.warning(f"âš ï¸ åŠ è½½è¯„è®ºå¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                data['comments'] = None
        else:
            data['comments'] = None
            
        if not data.get('comments'):
            logger.info("ğŸ’¬ ä»YouTubeè·å–è§†é¢‘è¯„è®º...")
            try:
                comments_data = self.youtube_client.get_video_comments(self.video_id, max_results=5)
                if comments_data and comments_data.get('items'):
                    comments = []
                    for item in comments_data['items']:
                        snippet = item['snippet']['topLevelComment']['snippet']
                        comments.append({
                            'text': snippet['textDisplay'],
                            'likes': snippet['likeCount'],
                            'author': snippet['authorDisplayName']
                        })
                    data['comments'] = sorted(comments, key=lambda x: x['likes'], reverse=True)[:5]
                    # ä¿å­˜è¯„è®º
                    with open(comments_file, 'w', encoding='utf-8') as f:
                        json.dump(data['comments'], f, ensure_ascii=False, indent=2)
                    logger.info(f"âœ… è·å–äº† {len(data['comments'])} æ¡çƒ­é—¨è¯„è®º")
                    logger.info(f"ğŸ’¾ è¯„è®ºå·²ç¼“å­˜åˆ°: {comments_file}")
                else:
                    data['comments'] = []
                    logger.warning("âš ï¸ æœªè·å–åˆ°è¯„è®º")
            except Exception as e:
                logger.warning(f"âš ï¸ è·å–è¯„è®ºå¤±è´¥ï¼ˆéè‡´å‘½ï¼‰: {e}")
                import traceback
                traceback.print_exc()
                data['comments'] = []
        
        # 3. è·å–æˆ–åŠ è½½å­—å¹•ï¼ˆè¿™æ˜¯å¿…éœ€çš„ï¼‰
        if subtitle_file.exists():
            logger.info("ğŸ“‚ å‘ç°å­—å¹•ç¼“å­˜ï¼Œä»æ–‡ä»¶åŠ è½½...")
            try:
                with open(subtitle_file, 'r', encoding='utf-8') as f:
                    data['subtitles'] = f.read()
                logger.info(f"âœ… åŠ è½½å­—å¹•æˆåŠŸï¼Œé•¿åº¦: {len(data['subtitles'])}å­—")
            except Exception as e:
                logger.warning(f"âš ï¸ åŠ è½½å­—å¹•å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                data['subtitles'] = None
        else:
            data['subtitles'] = None
            
        if not data.get('subtitles'):
            logger.info("ğŸ“ ä»YouTubeè·å–è§†é¢‘å­—å¹•...")
            try:
                result = self.youtube_client.get_video_transcript(self.video_id)
                if result:
                    # get_video_transcriptè¿”å›çš„æ˜¯å…ƒç»„: (relative_path, subtitle_text)
                    relative_path, subtitle_text = result
                    data['subtitles'] = subtitle_text
                    # ä¿å­˜å­—å¹•
                    with open(subtitle_file, 'w', encoding='utf-8') as f:
                        f.write(subtitle_text)
                    logger.info(f"âœ… è·å–å­—å¹•æˆåŠŸï¼Œé•¿åº¦: {len(subtitle_text)}å­—")
                    logger.info(f"ğŸ’¾ å­—å¹•å·²ç¼“å­˜åˆ°: {subtitle_file}")
                else:
                    logger.error("âŒ æ— æ³•è·å–å­—å¹•ï¼Œè¿™æ˜¯æ•…äº‹ç”Ÿæˆå¿…éœ€çš„")
                    return None
            except Exception as e:
                logger.error(f"âŒ è·å–å­—å¹•å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                return None
        
        # æ±‡æ€»ä¿¡æ¯
        logger.info("âœ… YouTubeæ•°æ®è·å–/åŠ è½½å®Œæˆï¼š")
        logger.info(f"  - è§†é¢‘æ ‡é¢˜: {data['video_info']['title']}")
        logger.info(f"  - è¯„è®ºæ•°: {len(data.get('comments', []))}")
        logger.info(f"  - å­—å¹•é•¿åº¦: {len(data.get('subtitles', ''))}å­—")
        
        return data
    
    def phase1_extract_dna(self, story_text: str) -> Tuple[str, Dict[str, Any]]:
        """
        ç¬¬ä¸€é˜¶æ®µï¼šæå–æ•…äº‹DNAå¹¶åˆ†ææ–‡æœ¬é•¿åº¦
        å¦‚æœå·²æœ‰å¤„ç†ç»“æœï¼Œåˆ™ä»æ–‡ä»¶åŠ è½½
        
        Args:
            story_text: åŸå§‹æ•…äº‹æ–‡æœ¬
            
        Returns:
            (æ•…äº‹DNAæ–‡æœ¬, æ–‡æœ¬åˆ†æå­—å…¸)
        """
        logger.info("ğŸ§¬ ç¬¬ä¸€é˜¶æ®µï¼šå¼€å§‹æå–æ•…äº‹DNA...")
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰å¤„ç†ç»“æœ
        dna_file = self.processing_dir / "1_story_dna.txt"
        if dna_file.exists():
            logger.info("ğŸ“‚ å‘ç°å·²æœ‰æ•…äº‹DNAï¼Œä»æ–‡ä»¶åŠ è½½...")
            try:
                with open(dna_file, 'r', encoding='utf-8') as f:
                    response = f.read()
                
                # è§£æå“åº”
                dna_data = self.text_processor.parse_story_dna(response)
                
                logger.info(f"âœ… ä»ç¼“å­˜åŠ è½½æ•…äº‹DNAæˆåŠŸ")
                return response, dna_data.get('text_analysis', {})
                
            except Exception as e:
                logger.warning(f"âš ï¸ åŠ è½½æ•…äº‹DNAå¤±è´¥ï¼Œå°†é‡æ–°ç”Ÿæˆ: {e}")
                import traceback
                traceback.print_exc()
        
        # æ„å»ºæç¤º
        prompt = f"{self.prompts['dna_extractor']}\n\n---\n\n{story_text}"
        
        # DEBUG: è®°å½•å®Œæ•´è¾“å…¥
        logger.debug("=" * 80)
        logger.debug("[DEBUG] phase1_extract_dna - AIè°ƒç”¨è¾“å…¥:")
        logger.debug(f"è¾“å…¥é•¿åº¦: {len(prompt)} å­—ç¬¦")
        logger.debug("å®Œæ•´è¾“å…¥å†…å®¹:")
        logger.debug("è¾“å…¥å†…å®¹ä¸ºåŸå§‹çš„dna_extractor å’Œ åŸå§‹çš„æ•…äº‹æ–‡æœ¬")
        logger.debug("=" * 80)
        
        try:
            # è°ƒç”¨Gemini API
            response = self.gemini_client.generate_content(prompt)
            
            # DEBUG: è®°å½•å®Œæ•´è¾“å‡º
            logger.debug("=" * 80)
            logger.debug("[DEBUG] phase1_extract_dna - AIè°ƒç”¨è¾“å‡º:")
            logger.debug(f"è¾“å‡ºé•¿åº¦: {len(response) if response else 0} å­—ç¬¦")
            if response:
                logger.debug("å®Œæ•´è¾“å‡ºå†…å®¹:")
                logger.debug(response)
            else:
                logger.debug("å“åº”ä¸ºç©º")
            logger.debug("=" * 80)
            
            if response:
                # ä¿å­˜åŸå§‹å“åº”
                with open(dna_file, 'w', encoding='utf-8') as f:
                    f.write(response)
                
                # è§£æå“åº”
                dna_data = self.text_processor.parse_story_dna(response)
                
                logger.info(f"âœ… æ•…äº‹DNAæå–æˆåŠŸ")
                
                # è¿”å›å®Œæ•´çš„DNAæ–‡æœ¬å’Œåˆ†ææ•°æ®
                return response, dna_data.get('text_analysis', {})
            else:
                logger.error("âŒ Gemini APIå“åº”ä¸ºç©º")
                return None, None
                
        except Exception as e:
            logger.error(f"âŒ æå–æ•…äº‹DNAå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None, None
    
    def phase2_generate_framework(self, story_dna: str, video_info: Dict, comments: List) -> str:
        """
        ç¬¬äºŒé˜¶æ®µï¼šç”Ÿæˆ9æ­¥æ•…äº‹æ”¹ç¼–æ¡†æ¶
        å¦‚æœå·²æœ‰å¤„ç†ç»“æœï¼Œåˆ™ä»æ–‡ä»¶åŠ è½½
        
        Args:
            story_dna: æ•…äº‹DNAæ–‡æœ¬
            video_info: è§†é¢‘ä¿¡æ¯
            comments: çƒ­é—¨è¯„è®º
            
        Returns:
            æ¡†æ¶æ–‡æœ¬
        """
        logger.info("ğŸ“‹ ç¬¬äºŒé˜¶æ®µï¼šå¼€å§‹ç”Ÿæˆæ•…äº‹æ”¹ç¼–æ¡†æ¶ï¼ˆ9æ­¥ç»“æ„ï¼‰...")
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰å¤„ç†ç»“æœ
        framework_file = self.processing_dir / "2_framework.txt"
        if framework_file.exists():
            logger.info("ğŸ“‚ å‘ç°å·²æœ‰æ¡†æ¶ï¼Œä»æ–‡ä»¶åŠ è½½...")
            try:
                with open(framework_file, 'r', encoding='utf-8') as f:
                    response = f.read()
                
                logger.info("âœ… ä»ç¼“å­˜åŠ è½½æ¡†æ¶æˆåŠŸ")
                return response
                
            except Exception as e:
                logger.warning(f"âš ï¸ åŠ è½½æ¡†æ¶å¤±è´¥ï¼Œå°†é‡æ–°ç”Ÿæˆ: {e}")
                import traceback
                traceback.print_exc()
        
        # å‡†å¤‡è¾“å…¥ - é€‚é…æ–°çš„æç¤ºè¯æ ¼å¼
        top_comments = [c['text'] for c in comments[:5]]
        
        # è®¡ç®—åŸæ•…äº‹å­—æ•°ï¼ˆä»å­—å¹•/DNAä¸­ä¼°ç®—ï¼‰
        original_word_count = len(story_dna) if story_dna else 5000
        
        input_data = f"""### åŸå§‹æ•…äº‹DNAä¸å…ƒæ•°æ®
- **åŸæ•…äº‹å‚è€ƒå­—æ•°ï¼š** {original_word_count}
- **åŸå§‹æ ‡é¢˜ï¼š** {video_info['title']}
- **çƒ­é—¨è¯„è®ºï¼ˆæ ¸å¿ƒæ§½ç‚¹æ¥æºï¼‰ï¼š**
{chr(10).join([f'  - {comment}' for comment in top_comments])}
- **æ•…äº‹DNAï¼š**
{story_dna}
"""
        
        # æ„å»ºæç¤º
        full_prompt = f"{self.prompts['framework_generator']}\n\n---\n\n{input_data}"
        
        # DEBUG: è®°å½•å®Œæ•´è¾“å…¥
        logger.debug("=" * 80)
        logger.debug("[DEBUG] phase2_generate_framework - AIè°ƒç”¨è¾“å…¥:")
        logger.debug(f"è¾“å…¥é•¿åº¦: {len(full_prompt)} å­—ç¬¦")
        logger.debug("å®Œæ•´è¾“å…¥å†…å®¹:")
        logger.debug(full_prompt)
        logger.debug("=" * 80)
        
        # æ·»åŠ é‡è¯•æœºåˆ¶
        max_retries = 1
        for attempt in range(max_retries):
            try:
                
                # è°ƒç”¨Gemini API
                response = self.gemini_client.generate_content(full_prompt)
                
                # DEBUG: è®°å½•å®Œæ•´è¾“å‡º
                logger.debug("=" * 80)
                logger.debug("[DEBUG] phase2_generate_framework - AIè°ƒç”¨è¾“å‡º:")
                logger.debug(f"å°è¯• {attempt + 1}/{max_retries}")
                logger.debug(f"è¾“å‡ºé•¿åº¦: {len(response) if response else 0} å­—ç¬¦")
                if response:
                    logger.debug("å®Œæ•´è¾“å‡ºå†…å®¹:")
                    logger.debug(response)
                else:
                    logger.debug("å“åº”ä¸ºç©º")
                logger.debug("=" * 80)
                
                if response:
                    # ä¿å­˜æ¡†æ¶
                    with open(framework_file, 'w', encoding='utf-8') as f:
                        f.write(response)
                    
                    logger.info("âœ… æ¡†æ¶ç”ŸæˆæˆåŠŸï¼ŒåŒ…å«30ä¸ªç‰‡æ®µçš„è¯¦ç»†è§„åˆ’")
                    return response
                else:
                    logger.error(f"âŒ å°è¯• {attempt + 1}/{max_retries} - Gemini APIå“åº”ä¸ºç©º, ç»ˆæ­¢æœåŠ¡")
                    sys.exit(1)
            except Exception as e:
                logger.error(f"âŒ å°è¯• {attempt + 1}/{max_retries} å¤±è´¥: {e}")
                import traceback
        logger.error("âŒ æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†")
        return None
    
    def phase3_generate_segments(self, story_dna: str, framework: str) -> List[str]:
        """
        ç¬¬ä¸‰é˜¶æ®µï¼šåˆ†æ®µç”Ÿ9ä¸ªç‰‡æ®µ
        æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼šå·²ç”Ÿæˆçš„ç‰‡æ®µä¼šä»æ–‡ä»¶åŠ è½½
        
        Args:
            story_dna: æ•…äº‹DNA
            framework: 9ä¸ªç‰‡æ®µçš„æ¡†æ¶
            
        Returns:
            ç”Ÿæˆçš„ç‰‡æ®µåˆ—è¡¨
        """
        logger.info("ğŸ“ ç¬¬ä¸‰é˜¶æ®µï¼šå¼€å§‹åˆ†æ®µç”Ÿæˆ30ä¸ªç‰‡æ®µ...")
        
        # è§£ææ¡†æ¶ä¸­çš„ç‰‡æ®µä¿¡æ¯
        segments_info = self.text_processor.parse_framework_segments(framework)
        if not segments_info:
            logger.error("âŒ æ— æ³•ä»æ¡†æ¶ä¸­è§£æç‰‡æ®µä¿¡æ¯")
            return None
        
        logger.info(f"ğŸ“Š è§£æå‡º {len(segments_info)} ä¸ªç‰‡æ®µè§„åˆ’")
        
        # è§£æç« èŠ‚ç»“æ„
        chapters = self.text_processor.parse_chapter_structure(framework)
        
        # åˆ›å»ºä¸Šä¸‹æ–‡ç®¡ç†å™¨
        context_manager = ContextManager()
        context_manager.add_global_context(story_dna, framework)
        
        # ç”Ÿæˆçš„ç‰‡æ®µåˆ—è¡¨
        segments = []
        
        # æ£€æŸ¥å·²å­˜åœ¨çš„ç‰‡æ®µæ–‡ä»¶
        existing_segments = {}
        for i in range(1, 31):  # æ£€æŸ¥ç‰‡æ®µ1-30
            segment_file = self.segments_dir / f"segment_{i:02d}.txt"
            if segment_file.exists():
                try:
                    with open(segment_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        if content.strip():  # ç¡®ä¿æ–‡ä»¶ä¸æ˜¯ç©ºçš„
                            existing_segments[i] = content
                            logger.info(f"ğŸ“‚ å‘ç°å·²å­˜åœ¨çš„ç‰‡æ®µ {i}ï¼Œé•¿åº¦: {len(content)}å­—")
                except Exception as e:
                    logger.warning(f"âš ï¸ è¯»å–ç‰‡æ®µ {i} å¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
        
        if existing_segments:
            logger.info(f"âœ… ä»ç¼“å­˜åŠ è½½äº† {len(existing_segments)} ä¸ªç‰‡æ®µ")
        
        # é€ä¸ªç”Ÿæˆç‰‡æ®µ
        for i, segment_info in enumerate(segments_info, 1):
            # ç‰¹æ®Šå¤„ç†Segment 1 - ä½¿ç”¨Frameworkä¸­çš„Opening Hook
            if i == 1 and i not in existing_segments:
                logger.info("ğŸ¯ ç‰‡æ®µ 1 ä½¿ç”¨Frameworkä¸­çš„Opening Hook...")
                opening_hook = self._extract_opening_hook_from_framework(framework)
                
                if opening_hook:
                    # ä¿å­˜Opening Hookä½œä¸ºSegment 1
                    segment_file = self.segments_dir / f"segment_{i:02d}.txt"
                    with open(segment_file, 'w', encoding='utf-8') as f:
                        f.write(opening_hook)
                    
                    segments.append(opening_hook)
                    
                    # æ·»åŠ åˆ°å¯¹è¯å†å²
                    segment_input = self.text_processor.build_segment_input(
                        segment_number=i,
                        segment_info=segment_info,
                        previous_segment=None
                    )
                    context_manager.add_segment_request(segment_input)
                    context_manager.add_segment_response(opening_hook)
                    
                    logger.info(f"âœ… ç‰‡æ®µ 1 å®Œæˆ (Opening Hook): {len(opening_hook)}å­—")
                    continue
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç¼“å­˜çš„ç‰‡æ®µ
            if i in existing_segments:
                # ä½¿ç”¨ç¼“å­˜çš„ç‰‡æ®µ
                cached_segment = existing_segments[i]
                segments.append(cached_segment)
                
                # æ·»åŠ åˆ°å¯¹è¯å†å²ï¼ˆé‡å»ºå†å²ä¸Šä¸‹æ–‡ï¼‰
                segment_input = self.text_processor.build_segment_input(
                    segment_number=i,
                    segment_info=segment_info,
                    previous_segment=segments[-2] if len(segments) > 1 else None
                )
                context_manager.add_segment_request(segment_input)
                context_manager.add_segment_response(cached_segment)
                
                logger.info(f"âœ… ä½¿ç”¨ç¼“å­˜çš„ç‰‡æ®µ {i}: {segment_info.get('title', '')} ({len(cached_segment)}å­—)")
                continue
            
            # éœ€è¦ç”Ÿæˆæ–°ç‰‡æ®µ
            # ç¡®å®šæ‰€å±ç« èŠ‚
            segment_chapter = None
            for chapter_name, segment_ids in chapters.items():
                if i in segment_ids:
                    segment_chapter = chapter_name
                    break
            
            segment_info['chapter'] = segment_chapter or "æœªåˆ†ç±»"
            
            logger.info(f"ğŸ”„ ç”Ÿæˆç‰‡æ®µ {i}/{len(segments_info)}: {segment_info.get('title', '')}")
            
            # æ„å»ºè¾“å…¥
            segment_input = self.text_processor.build_segment_input(
                segment_number=i,
                segment_info=segment_info,
                previous_segment=segments[-1] if segments else None
            )
            
            # æ·»åŠ åˆ°å¯¹è¯å†å²
            context_manager.add_segment_request(segment_input)
            
            try:
                # DEBUG: è®°å½•ç‰‡æ®µç”Ÿæˆè¾“å…¥
                logger.debug("=" * 80)
                logger.debug(f"[DEBUG] phase3_generate_segments - ç‰‡æ®µ{i}è¾“å…¥:")
                logger.debug(f"è¾“å…¥é•¿åº¦: {len(segment_input)} å­—ç¬¦")
                logger.debug("è¾“å…¥å†…å®¹:")
                logger.debug(segment_input)
                logger.debug(f"å†å²è®°å½•æ¡æ•°: {len(context_manager.get_history())}")
                logger.debug("=" * 80)
                
                # è°ƒç”¨Gemini APIï¼Œä¼ å…¥å®Œæ•´çš„å¯¹è¯å†å²
                response = self.gemini_client.generate_content_with_history(
                    prompt=segment_input,
                    history=context_manager.get_history()
                )
                
                # DEBUG: è®°å½•ç‰‡æ®µç”Ÿæˆè¾“å‡º
                logger.debug("=" * 80)
                logger.debug(f"[DEBUG] phase3_generate_segments - ç‰‡æ®µ{i}è¾“å‡º:")
                logger.debug(f"è¾“å‡ºé•¿åº¦: {len(response) if response else 0} å­—ç¬¦")
                if response:
                    logger.debug("å®Œæ•´è¾“å‡ºå†…å®¹:")
                    logger.debug(response)
                else:
                    logger.debug("å“åº”ä¸ºç©º")
                logger.debug("=" * 80)
                
                if response:
                    # ä¿å­˜ç‰‡æ®µ
                    segment_file = self.segments_dir / f"segment_{i:02d}.txt"
                    with open(segment_file, 'w', encoding='utf-8') as f:
                        f.write(response)
                    
                    segments.append(response)
                    
                    # æ·»åŠ åˆ°å¯¹è¯å†å²
                    context_manager.add_segment_response(response)
                    
                    # è®¡ç®—å­—æ•°
                    word_count = len(response)
                    target = segment_info.get('length', 1000)
                    deviation = ((word_count - target) / target) * 100
                    
                    logger.info(f"âœ… ç‰‡æ®µ {i} å®Œæˆ: {word_count}å­— (ç›®æ ‡{target}å­—, åå·®{deviation:+.1f}%)")
                    
                    # æ¯5ä¸ªç‰‡æ®µä¼‘æ¯ä¸€ä¸‹ï¼Œé¿å…APIé™åˆ¶
                    if i % 5 == 0 and i not in existing_segments:
                        logger.info("â¸ï¸ æš‚åœ2ç§’...")
                        time.sleep(2)
                else:
                    logger.error(f"âŒ ç‰‡æ®µ {i} ç”Ÿæˆå¤±è´¥")
                    # ä½¿ç”¨å ä½ç¬¦
                    segments.append(f"[ç‰‡æ®µ{i}ç”Ÿæˆå¤±è´¥]")
                    
            except Exception as e:
                logger.error(f"âŒ ç”Ÿæˆç‰‡æ®µ {i} æ—¶å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
                segments.append(f"[ç‰‡æ®µ{i}ç”Ÿæˆå¤±è´¥: {str(e)}]")
        
        logger.info(f"âœ… å®Œæˆæ‰€æœ‰ç‰‡æ®µç”Ÿæˆï¼Œå…± {len(segments)} ä¸ªç‰‡æ®µ")
        return segments
    
    def phase3_generate_segments_simple(self, story_dna: str, framework: str) -> List[str]:
        """
        ç®€åŒ–ç‰ˆç‰‡æ®µç”Ÿæˆ - æ‰‹åŠ¨æ§åˆ¶ä¸Šä¸‹æ–‡ï¼Œä¸ä½¿ç”¨èŠå¤©å†å²
        æ¯ä¸ªç‰‡æ®µéƒ½æ˜¯ç‹¬ç«‹çš„APIè°ƒç”¨ï¼Œåªä¼ é€’å‰500å­—ç”¨äºè¡”æ¥
        
        Args:
            story_dna: æ•…äº‹DNA
            framework: æ•…äº‹æ”¹ç¼–æ¡†æ¶
            
        Returns:
            ç”Ÿæˆçš„ç‰‡æ®µåˆ—è¡¨
        """
        logger.info(f"ğŸ“ ç¬¬ä¸‰é˜¶æ®µï¼šå¼€å§‹ç”Ÿæˆæ•…äº‹ç‰‡æ®µï¼ˆç®€åŒ–ç‰ˆï¼Œå…±{self.num_segments}ä¸ªç‰‡æ®µï¼‰...")
        
        # 1. ä»æ¡†æ¶æå–å¿…è¦ä¿¡æ¯
        framework_summary = self.extract_framework_summary(framework)
        segment_tasks = self.extract_segment_tasks(framework)
        
        # 2. æå–9æ­¥æ¡†æ¶çš„å®Œæ•´å†…å®¹
        framework_steps = self.extract_9steps_full_content(framework)
        
        segments = []
        
        for i in range(1, self.num_segments + 1):
            # æ£€æŸ¥ç¼“å­˜
            segment_file = self.segments_dir / f"segment_{i:02d}.txt"
            if segment_file.exists():
                try:
                    with open(segment_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        if content.strip():
                            segments.append(content)
                            logger.info(f"ğŸ“‚ ä½¿ç”¨ç¼“å­˜çš„ç‰‡æ®µ {i}, é•¿åº¦: {len(content)}å­—")
                            continue
                except Exception as e:
                    logger.warning(f"âš ï¸ è¯»å–ç‰‡æ®µ {i} å¤±è´¥: {e}")
            
            # 3. è·å–å½“å‰ç‰‡æ®µå¯¹åº”çš„æ¡†æ¶å†…å®¹
            segment_task = segment_tasks.get(i, {})
            # ç›´æ¥ä½¿ç”¨æ¡†æ¶ä¸­å¯¹åº”æ­¥éª¤çš„åŸå§‹å†…å®¹
            segment_task['framework_step_content'] = framework_steps.get(i, f"- **æ®µè½ç¼–å·ï¼š** ç¬¬ {i} æ®µ")
            
            # 4. æ„å»ºè¾“å…¥ï¼ˆå®Œå…¨æ‰‹åŠ¨æ§åˆ¶ï¼‰
            segment_input = self.build_segment_input_simple(
                segment_num=i,
                framework_summary=framework_summary,
                previous_text=segments[-1][-500:] if segments else "",
                segment_task=segment_task
            )
            
            # 3. ç”Ÿæˆç‰‡æ®µï¼ˆç‹¬ç«‹çš„APIè°ƒç”¨ï¼‰
            try:
                logger.info(f"ğŸ”„ ç”Ÿæˆç‰‡æ®µ {i}/{self.num_segments}: {segment_tasks.get(i, {}).get('chapter', '')}")
                
                # DEBUG: è®°å½•è¾“å…¥
                logger.debug("=" * 80)
                logger.debug(f"[DEBUG] ç‰‡æ®µ{i}è¾“å…¥:")
                logger.debug(f"è¾“å…¥é•¿åº¦: {len(segment_input)} å­—ç¬¦")
                logger.debug("è¾“å…¥å†…å®¹:")
                logger.debug(segment_input)
                logger.debug("=" * 80)
                
                response = self.gemini_client.generate_content(segment_input)
                
                # DEBUG: è®°å½•è¾“å‡º
                logger.debug("=" * 80)
                logger.debug(f"[DEBUG] ç‰‡æ®µ{i}è¾“å‡º:")
                logger.debug(f"è¾“å‡ºé•¿åº¦: {len(response) if response else 0} å­—ç¬¦")
                if response:
                    logger.debug("è¾“å‡ºå†…å®¹:")
                    logger.debug(response)
                else:
                    logger.debug("å“åº”ä¸ºç©º")
                logger.debug("=" * 80)
                
                if response:
                    segments.append(response)
                    # ä¿å­˜ç‰‡æ®µ
                    with open(segment_file, 'w', encoding='utf-8') as f:
                        f.write(response)
                    
                    logger.info(f"âœ… ç‰‡æ®µ {i} ç”Ÿæˆå®Œæˆ: {len(response)}å­—")
                    
                    # é€‚å½“ä¼‘æ¯é¿å…é™æµ
                    if i % 5 == 0:
                        logger.info("â¸ï¸ æš‚åœ2ç§’...")
                        time.sleep(2)
                else:
                    logger.error(f"âŒ ç‰‡æ®µ {i} ç”Ÿæˆå¤±è´¥")
                    segments.append(f"[ç‰‡æ®µ{i}ç”Ÿæˆå¤±è´¥]")
                    
            except Exception as e:
                logger.error(f"âŒ ç”Ÿæˆç‰‡æ®µ {i} æ—¶å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
                segments.append(f"[ç‰‡æ®µ{i}ç”Ÿæˆå¤±è´¥: {str(e)}]")
        
        logger.info(f"âœ… å®Œæˆæ‰€æœ‰ç‰‡æ®µç”Ÿæˆï¼Œå…± {len(segments)} ä¸ªç‰‡æ®µ")
        return segments
    
    def build_segment_input_simple(self, segment_num: int, framework_summary: str, 
                                   previous_text: str, segment_task: dict) -> str:
        """
        æ„å»ºç‰‡æ®µç”Ÿæˆçš„è¾“å…¥ - ç®€å•ç›´æ¥
        
        Args:
            segment_num: ç‰‡æ®µç¼–å·
            framework_summary: æ¡†æ¶æ‘˜è¦
            previous_text: å‰ä¸€æ®µçš„æœ€å500å­—
            segment_task: å½“å‰ç‰‡æ®µçš„ä»»åŠ¡ä¿¡æ¯
            
        Returns:
            æ„å»ºå¥½çš„è¾“å…¥æ–‡æœ¬
        """
        # è¯»å–segment_generatoræç¤ºè¯
        segment_prompt = self.prompts.get('segment_generator', '')
        
        # æ ¹æ®æ–°çš„æç¤ºè¯æ ¼å¼æ„å»ºè¾“å…¥
        input_text = f"""{segment_prompt}

==================================================
**æœ€é«˜æŒ‡ä»¤ï¼šæ•…äº‹æ”¹ç¼–æ¡†æ¶ V2.1 (æ‘˜è¦)**
==================================================
{framework_summary}

==================================================
**å‰ä¸€æ®µå†…å®¹ (Previous Segment)**
==================================================
{previous_text if previous_text else "**This is the first segment.**"}

==================================================
**æœ¬æ®µä»»åŠ¡å¡ (Current Segment Task Card)**
==================================================
{segment_task.get('framework_step_content', f"- **æ®µè½ç¼–å·ï¼š** ç¬¬ {segment_num} æ®µ")}
"""
        
        return input_text
    
    def extract_9steps_full_content(self, framework: str) -> dict:
        """
        ä»æ¡†æ¶ä¸­æå–9æ­¥çš„å®Œæ•´å†…å®¹ï¼ˆä¿æŒåŸå§‹æ ¼å¼ï¼‰
        
        Args:
            framework: æ¡†æ¶æ–‡æœ¬
            
        Returns:
            {step_num: full_content} å­—å…¸
        """
        import re
        
        steps_content = {}
        
        # æŸ¥æ‰¾"B. æ•…äº‹è“å›¾"éƒ¨åˆ†
        blueprint_match = re.search(r'## B\. æ•…äº‹è“å›¾.*?\n(.*?)(?=##|$)', framework, re.DOTALL)
        if not blueprint_match:
            # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•å…¶ä»–æ ¼å¼
            blueprint_match = re.search(r'æ•…äº‹è“å›¾.*?\n(.*?)(?=##|$)', framework, re.DOTALL)
        
        if blueprint_match:
            blueprint_text = blueprint_match.group(1)
            
            # åŒ¹é…æ¯ä¸ªæ­¥éª¤ï¼Œä¿æŒåŸå§‹æ ¼å¼
            # æ ¼å¼: - **N. æ­¥éª¤åç§° (è‹±æ–‡)ï¼š**
            pattern = r'(- \*\*(\d+)\. [^*]+\*\*.*?)(?=- \*\*\d+\.|$)'
            
            matches = re.findall(pattern, blueprint_text, re.DOTALL)
            
            for full_match, step_num in matches:
                step_num = int(step_num)
                # ä¿å­˜å®Œæ•´å†…å®¹ï¼Œä¿æŒåŸå§‹æ ¼å¼
                steps_content[step_num] = full_match.strip()
        
        return steps_content
    
    def extract_framework_summary(self, framework: str) -> str:
        """
        ä»æ–°ç‰ˆframeworkæå–æ‘˜è¦ä¿¡æ¯
        
        Args:
            framework: æ¡†æ¶æ–‡æœ¬
            
        Returns:
            æ¡†æ¶æ‘˜è¦
        """
        import re
        
        summary_parts = []
        
        # æå–æ ¸å¿ƒæ”¹ç¼–ç†å¿µ
        if match := re.search(r'æ ¸å¿ƒæ”¹ç¼–ç†å¿µï¼š\*\*\s*(.+)', framework):
            summary_parts.append(f"- **æ ¸å¿ƒæ”¹ç¼–ç†å¿µï¼š** {match.group(1)}")
        
        # æå–æ§½ç‚¹ç­–ç•¥
        if match := re.search(r'è¯†åˆ«å‡ºçš„æ ¸å¿ƒæ§½ç‚¹ï¼š\*\*\s*(.+)', framework):
            summary_parts.append(f"- **æ§½ç‚¹ç­–ç•¥ï¼š** {match.group(1)}")
        
        if match := re.search(r'æ”¾å¤§æ–¹æ¡ˆï¼š\*\*\s*(.+)', framework):
            summary_parts.append(f"- **æ”¾å¤§æ–¹æ¡ˆï¼š** {match.group(1)}")
        
        # æå–9æ­¥ç»“æ„ç®€è¿°
        nine_steps = []
        for step in ['é’©å­å¼€åœº', 'è§’è‰²ä¸åŠ¨æœº', 'æ„å¤–è½¬æŠ˜', 'å°è¯•ä¸å¤±è´¥', 
                     'æƒ…ç»ªä½è°·', 'é¡¿æ‚Ÿä¸è½¬å˜', 'æœ€ç»ˆè¡ŒåŠ¨', 'èƒœåˆ©çš„ä»£ä»·', 'æ–°çš„æ‚¬å¿µ']:
            if step in framework:
                nine_steps.append(step)
        
        if nine_steps:
            summary_parts.append(f"- **9æ­¥ç»“æ„ï¼š** {', '.join(nine_steps)}")
        
        # æå–è§’è‰²åå­—
        characters = re.findall(r'è§’è‰²\d+ï¼š\[([^\]]+)\]', framework)
        if characters:
            summary_parts.append(f"- **è§’è‰²åå†Œï¼š** {', '.join(characters)}")
        
        return '\n'.join(summary_parts) if summary_parts else "- **æ ¸å¿ƒç†å¿µï¼š** æ”¹ç¼–æ•…äº‹"
    
    def extract_segment_tasks(self, framework: str) -> dict:
        """
        ä»9æ­¥ç»“æ„æ˜ å°„åˆ°ç‰‡æ®µçš„ä»»åŠ¡
        
        Args:
            framework: æ¡†æ¶æ–‡æœ¬
            
        Returns:
            ç‰‡æ®µä»»åŠ¡å­—å…¸ {segment_num: task_info}
        """
        tasks = {}
        
        # ä»æ¡†æ¶ä¸­æå–æ¯æ­¥çš„å…·ä½“å†…å®¹
        step_contents = self.parse_nine_steps(framework)
        
        if self.num_segments == 9:
            # 9ä¸ªç‰‡æ®µæ—¶ï¼Œæ¯æ­¥å¯¹åº”ä¸€ä¸ªç‰‡æ®µ
            step_names = ['é’©å­å¼€åœº', 'è§’è‰²ä¸åŠ¨æœº', 'æ„å¤–è½¬æŠ˜', 'å°è¯•ä¸å¤±è´¥', 
                         'æƒ…ç»ªä½è°·', 'é¡¿æ‚Ÿä¸è½¬å˜', 'æœ€ç»ˆè¡ŒåŠ¨', 'èƒœåˆ©çš„ä»£ä»·', 'æ–°çš„æ‚¬å¿µ']
            
            for i in range(1, 10):
                if i <= len(step_names):
                    step_name = step_names[i-1]
                    step_data = step_contents.get(step_name, {})
                    task_info = {
                        'chapter': step_name,
                        'task': step_data.get('æƒ…èŠ‚è§„åˆ’', f'{step_name}é˜¶æ®µ')
                    }
                    
                    # æ·»åŠ èŠ‚å¥ä¸å­—æ•°ä¿¡æ¯
                    if 'èŠ‚å¥ä¸å­—æ•°' in step_data:
                        task_info['rhythm'] = step_data['èŠ‚å¥ä¸å­—æ•°']
                    
                    # æ·»åŠ å…·ä½“å­—æ•°èŒƒå›´
                    if 'å­—æ•°èŒƒå›´' in step_data:
                        min_words, max_words = step_data['å­—æ•°èŒƒå›´']
                        task_info['word_count_range'] = (min_words, max_words)
                        task_info['target_words'] = (min_words + max_words) // 2  # ç›®æ ‡å­—æ•°å–ä¸­é—´å€¼
                    
                    tasks[i] = task_info
        else:
            # å¦‚æœæ˜¯å…¶ä»–æ•°é‡çš„ç‰‡æ®µï¼Œä½¿ç”¨æ¯”ä¾‹åˆ†é…
            # 30ç‰‡æ®µçš„åŸå§‹æ˜ å°„
            MAPPING_30 = {
                (1, 2): ('é’©å­å¼€åœº', 'å¿«èŠ‚å¥ï¼Œæ‚¬å¿µä¸›ç”Ÿ', 700),
                (3, 5): ('è§’è‰²ä¸åŠ¨æœº', 'ä¸­ç­‰èŠ‚å¥ï¼Œäººç‰©åˆ»ç”»', 1000),
                (6, 8): ('æ„å¤–è½¬æŠ˜', 'èŠ‚å¥åŠ å¿«ï¼Œåˆ¶é€ å†²å‡»', 900),
                (9, 13): ('å°è¯•ä¸å¤±è´¥', 'åŠ¨ä½œä¸å†…å¿ƒæˆç»“åˆ', 1200),
                (14, 17): ('æƒ…ç»ªä½è°·', 'æ…¢èŠ‚å¥ï¼Œæƒ…ç»ªæ¸²æŸ“', 1100),
                (18, 20): ('é¡¿æ‚Ÿä¸è½¬å˜', 'è½¬æŠ˜ç‚¹ï¼ŒèŠ‚å¥ç”±æ…¢è½¬å¿«', 900),
                (21, 26): ('æœ€ç»ˆè¡ŒåŠ¨', 'æå¿«èŠ‚å¥ï¼ŒåŠ¨ä½œå¯†é›†', 1500),
                (27, 29): ('èƒœåˆ©çš„ä»£ä»·', 'èŠ‚å¥æ”¾ç¼“ï¼Œå¸¦åæ€', 1100),
                (30, 30): ('æ–°çš„æ‚¬å¿µ', 'çŸ­å°ç²¾æ‚ï¼Œåˆ¶é€ æ‚¬å¿µ', 500)
            }
            
            # æŒ‰æ¯”ä¾‹åˆ†é…ç‰‡æ®µ
            for segment in range(1, self.num_segments + 1):
                # è®¡ç®—å½“å‰ç‰‡æ®µå¯¹åº”30ç‰‡æ®µä½“ç³»çš„ä½ç½®
                position_30 = int((segment - 1) * 30 / self.num_segments) + 1
                
                for (start, end), (step_name, rhythm, words) in MAPPING_30.items():
                    if start <= position_30 <= end:
                        step_data = step_contents.get(step_name, {})
                        task_info = {
                            'chapter': step_name,
                            'task': step_data.get('æƒ…èŠ‚è§„åˆ’', f'{step_name}é˜¶æ®µ'),
                            'rhythm': step_data.get('èŠ‚å¥ä¸å­—æ•°', f"{rhythm}ã€‚çº¦{words}å­—")
                        }
                        
                        # å¦‚æœæ¡†æ¶ä¸­æœ‰å…·ä½“å­—æ•°èŒƒå›´ï¼Œä½¿ç”¨æ¡†æ¶çš„ï¼›å¦åˆ™ä½¿ç”¨é»˜è®¤å€¼
                        if 'å­—æ•°èŒƒå›´' in step_data:
                            min_words, max_words = step_data['å­—æ•°èŒƒå›´']
                            task_info['word_count_range'] = (min_words, max_words)
                            task_info['target_words'] = (min_words + max_words) // 2
                        else:
                            task_info['target_words'] = words
                        
                        tasks[segment] = task_info
                        break
        
        return tasks
    
    def _get_rhythm_for_step(self, step_name: str) -> str:
        """è·å–æ¯ä¸ªæ­¥éª¤çš„èŠ‚å¥è¯´æ˜"""
        rhythms = {
            'é’©å­å¼€åœº': 'å¿«èŠ‚å¥ï¼Œæ‚¬å¿µä¸›ç”Ÿ',
            'è§’è‰²ä¸åŠ¨æœº': 'ä¸­ç­‰èŠ‚å¥ï¼Œäººç‰©åˆ»ç”»',
            'æ„å¤–è½¬æŠ˜': 'èŠ‚å¥åŠ å¿«ï¼Œåˆ¶é€ å†²å‡»',
            'å°è¯•ä¸å¤±è´¥': 'åŠ¨ä½œä¸å†…å¿ƒæˆç»“åˆ',
            'æƒ…ç»ªä½è°·': 'æ…¢èŠ‚å¥ï¼Œæƒ…ç»ªæ¸²æŸ“',
            'é¡¿æ‚Ÿä¸è½¬å˜': 'è½¬æŠ˜ç‚¹ï¼ŒèŠ‚å¥ç”±æ…¢è½¬å¿«',
            'æœ€ç»ˆè¡ŒåŠ¨': 'æå¿«èŠ‚å¥ï¼ŒåŠ¨ä½œå¯†é›†',
            'èƒœåˆ©çš„ä»£ä»·': 'èŠ‚å¥æ”¾ç¼“ï¼Œå¸¦åæ€',
            'æ–°çš„æ‚¬å¿µ': 'çŸ­å°ç²¾æ‚ï¼Œåˆ¶é€ æ‚¬å¿µ'
        }
        return rhythms.get(step_name, 'æ­£å¸¸èŠ‚å¥')
    
    def parse_nine_steps(self, framework: str) -> dict:
        """
        è§£æ9æ­¥ç»“æ„çš„å…·ä½“å†…å®¹
        
        Args:
            framework: æ¡†æ¶æ–‡æœ¬
            
        Returns:
            9æ­¥å†…å®¹å­—å…¸
        """
        import re
        steps = {}
        
        # æ›´å®Œæ•´çš„æ¨¡å¼åŒ¹é…ï¼ŒåŒæ—¶æå–æƒ…èŠ‚è§„åˆ’å’ŒèŠ‚å¥ä¸å­—æ•°
        # æ ¼å¼: **1. é’©å­å¼€åœº (Hook)ï¼š**
        #       - **æƒ…èŠ‚è§„åˆ’ï¼š** [å†…å®¹]
        #       - **èŠ‚å¥ä¸å­—æ•°ï¼š** [å†…å®¹]
        pattern = r'\*\*(\d+)\.\s+([^(]+)\s*\([^)]+\)ï¼š\*\*([^*]*?)(?=\*\*\d+\.|$)'
        
        matches = re.findall(pattern, framework, re.DOTALL)
        for step_num, step_name, content in matches:
            step_name = step_name.strip()
            steps[step_name] = {}
            
            # æå–æƒ…èŠ‚è§„åˆ’
            plot_match = re.search(r'\*\*æƒ…èŠ‚è§„åˆ’ï¼š\*\*\s*([^\n]+(?:\n(?!\s*-\s*\*\*)[^\n]+)*)', content)
            if plot_match:
                steps[step_name]['æƒ…èŠ‚è§„åˆ’'] = plot_match.group(1).strip()
            
            # æå–èŠ‚å¥ä¸å­—æ•°
            rhythm_match = re.search(r'\*\*èŠ‚å¥ä¸å­—æ•°ï¼š\*\*\s*([^\n]+)', content)
            if rhythm_match:
                rhythm_text = rhythm_match.group(1).strip()
                steps[step_name]['èŠ‚å¥ä¸å­—æ•°'] = rhythm_text
                
                # æå–å…·ä½“å­—æ•°èŒƒå›´
                word_count_match = re.search(r'(\d+)[-â€“](\d+)\s*å­—', rhythm_text)
                if word_count_match:
                    min_words = int(word_count_match.group(1))
                    max_words = int(word_count_match.group(2))
                    steps[step_name]['å­—æ•°èŒƒå›´'] = (min_words, max_words)
        
        # å¦‚æœä¸Šé¢çš„æ¨¡å¼åŒ¹é…å¤±è´¥ï¼Œå°è¯•æ›´ç®€å•çš„æ¨¡å¼
        if not steps:
            # å°è¯•åŒ¹é…: 1. é’©å­å¼€åœº (Hook)
            simple_pattern = r'\d+\.\s*([^(]+)\s*\([^)]+\)'
            simple_matches = re.findall(simple_pattern, framework)
            for step_name in simple_matches:
                step_name = step_name.strip()
                steps[step_name] = {'æƒ…èŠ‚è§„åˆ’': f'{step_name}é˜¶æ®µ'}
        
        return steps
    
    def phase4_concat_segments(self, segments: List[str]) -> str:
        """
        ç¬¬å››é˜¶æ®µï¼šæ‹¼æ¥æ‰€æœ‰ç‰‡æ®µ
        å¦‚æœå·²æœ‰è‰ç¨¿æ–‡ä»¶ï¼Œåˆ™ä»æ–‡ä»¶åŠ è½½
        
        Args:
            segments: ç‰‡æ®µåˆ—è¡¨
            
        Returns:
            å®Œæ•´æ•…äº‹æ–‡æœ¬
        """
        logger.info("ğŸ”— ç¬¬å››é˜¶æ®µï¼šæ‹¼æ¥æ‰€æœ‰ç‰‡æ®µ...")
        
        draft_file = self.processing_dir / "3_draft.txt"
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰è‰ç¨¿
        if draft_file.exists():
            logger.info("ğŸ“‚ å‘ç°å·²æœ‰è‰ç¨¿æ–‡ä»¶ï¼Œä»æ–‡ä»¶åŠ è½½...")
            try:
                with open(draft_file, 'r', encoding='utf-8') as f:
                    full_story = f.read()
                
                if full_story.strip():
                    logger.info(f"âœ… ä»ç¼“å­˜åŠ è½½è‰ç¨¿æˆåŠŸï¼Œé•¿åº¦: {len(full_story)}å­—")
                    return full_story
                    
            except Exception as e:
                logger.warning(f"âš ï¸ åŠ è½½è‰ç¨¿å¤±è´¥ï¼Œå°†é‡æ–°æ‹¼æ¥: {e}")
                import traceback
                traceback.print_exc()
        
        # éœ€è¦é‡æ–°æ‹¼æ¥
        # åˆå¹¶ç‰‡æ®µ
        full_story = self.text_processor.merge_segments(segments)
        
        # ä¿å­˜è‰ç¨¿
        with open(draft_file, 'w', encoding='utf-8') as f:
            f.write(full_story)
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_words = len(full_story)
        logger.info(f"âœ… æ‹¼æ¥å®Œæˆï¼Œæ€»é•¿åº¦: {total_words}å­—")
        
        return full_story
    
    def phase5_polish(self, framework: str, draft: str) -> str:
        """
        ç¬¬äº”é˜¶æ®µï¼šæœ€ç»ˆæ¶¦è‰²ï¼ˆä½¿ç”¨ä¸­æ–‡ç‰ˆæœ¬ï¼‰
        å¦‚æœå·²æœ‰æ¶¦è‰²ç»“æœï¼Œåˆ™ä»æ–‡ä»¶åŠ è½½
        
        Args:
            framework: æ”¹ç¼–æ¡†æ¶
            draft: æ•…äº‹è‰ç¨¿
            
        Returns:
            æ¶¦è‰²åçš„æ•…äº‹
        """
        logger.info("âœ¨ ç¬¬äº”é˜¶æ®µï¼šå¼€å§‹æœ€ç»ˆæ¶¦è‰²ï¼ˆä¸­æ–‡ç‰ˆï¼‰...")
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ¶¦è‰²ç»“æœ
        polished_file = self.processing_dir / "4_polished.txt"
        final_story_file = self.final_dir / "story.txt"
        
        if polished_file.exists() and final_story_file.exists():
            logger.info("ğŸ“‚ å‘ç°å·²æœ‰æ¶¦è‰²ç»“æœï¼Œä»æ–‡ä»¶åŠ è½½...")
            try:
                with open(final_story_file, 'r', encoding='utf-8') as f:
                    final_story = f.read()
                
                if final_story.strip():
                    logger.info(f"âœ… ä»ç¼“å­˜åŠ è½½æ¶¦è‰²æ•…äº‹æˆåŠŸï¼Œé•¿åº¦: {len(final_story)}å­—")
                    return final_story
                    
            except Exception as e:
                logger.warning(f"âš ï¸ åŠ è½½æ¶¦è‰²ç»“æœå¤±è´¥ï¼Œå°†é‡æ–°ç”Ÿæˆ: {e}")
                import traceback
                traceback.print_exc()
        
        # éœ€è¦é‡æ–°æ¶¦è‰²
        # æ„å»ºè¾“å…¥
        polish_input = self.text_processor.format_polish_input(framework, draft, num_segments=self.num_segments)
        
        # æ„å»ºå®Œæ•´æç¤º
        full_prompt = f"{self.prompts['final_polisher']}\n\n---\n\n{polish_input}"
        
        # DEBUG: è®°å½•å®Œæ•´è¾“å…¥
        logger.debug("=" * 80)
        logger.debug("[DEBUG] phase5_polish - AIè°ƒç”¨è¾“å…¥:")
        logger.debug(f"è¾“å…¥é•¿åº¦: {len(full_prompt)} å­—ç¬¦")
        logger.debug("å®Œæ•´è¾“å…¥å†…å®¹:")
        logger.debug(full_prompt)
        logger.debug("=" * 80)
        
        try:
            # è°ƒç”¨Gemini API
            response = self.gemini_client.generate_content(full_prompt)
            
            # DEBUG: è®°å½•å®Œæ•´è¾“å‡º
            logger.debug("=" * 80)
            logger.debug("[DEBUG] phase5_polish - AIè°ƒç”¨è¾“å‡º:")
            logger.debug(f"è¾“å‡ºé•¿åº¦: {len(response) if response else 0} å­—ç¬¦")
            if response:
                logger.debug("å®Œæ•´è¾“å‡ºå†…å®¹:")
                logger.debug(response)
            else:
                logger.debug("å“åº”ä¸ºç©º")
            logger.debug("=" * 80)
            
            if response:
                # ä¿å­˜æ¶¦è‰²ç»“æœ
                with open(polished_file, 'w', encoding='utf-8') as f:
                    f.write(response)
                
                # è§£æè¾“å‡º
                polish_result = self.text_processor.parse_polish_output(response)
                
                # ä¿å­˜æœ€ç»ˆæ•…äº‹
                final_story = polish_result.get('story', draft)
                with open(final_story_file, 'w', encoding='utf-8') as f:
                    f.write(final_story)
                
                # ä¿å­˜ç¼–è¾‘æŠ¥å‘Š
                if 'report' in polish_result:
                    with open(self.final_dir / "edit_report.txt", 'w', encoding='utf-8') as f:
                        f.write(polish_result['report'])
                
                logger.info(f"âœ… æ¶¦è‰²å®Œæˆï¼Œæœ€ç»ˆé•¿åº¦: {len(final_story)}å­—")
                return final_story
            else:
                logger.error("âŒ Gemini APIå“åº”ä¸ºç©º")
                return draft
                
        except Exception as e:
            logger.error(f"âŒ æ¶¦è‰²å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return draft
    
    def generate_final_report(self):
        """ç”Ÿæˆè¯¦ç»†çš„æœ€ç»ˆæŠ¥å‘Šï¼ŒåŒ…å«AIæ€»ç»“åˆ†æ"""
        logger.info("ğŸ“Š ç”Ÿæˆè¯¦ç»†æœ€ç»ˆæŠ¥å‘Š...")
        
        # è¯»å–å„é˜¶æ®µçš„æ–‡ä»¶å†…å®¹
        dna_content = ""
        framework_content = ""
        original_story = ""
        final_story = ""
        edit_report = ""
        video_info = {}
        
        try:
            # è¯»å–DNAæ–‡ä»¶
            dna_file = self.processing_dir / "1_story_dna.txt"
            if dna_file.exists():
                with open(dna_file, 'r', encoding='utf-8') as f:
                    dna_content = f.read()
            
            # è¯»å–æ¡†æ¶æ–‡ä»¶
            framework_file = self.processing_dir / "2_framework.txt"
            if framework_file.exists():
                with open(framework_file, 'r', encoding='utf-8') as f:
                    framework_content = f.read()
            
            # è¯»å–åŸå§‹æ•…äº‹
            original_story_file = self.raw_dir / "subtitle.txt"
            if original_story_file.exists():
                with open(original_story_file, 'r', encoding='utf-8') as f:
                    original_story = f.read()
            
            # è¯»å–æœ€ç»ˆæ•…äº‹
            final_story_file = self.final_dir / "story.txt"
            if final_story_file.exists():
                with open(final_story_file, 'r', encoding='utf-8') as f:
                    final_story = f.read()
            
            # è¯»å–ç¼–è¾‘æŠ¥å‘Š
            edit_report_file = self.final_dir / "edit_report.txt"
            if edit_report_file.exists():
                with open(edit_report_file, 'r', encoding='utf-8') as f:
                    edit_report = f.read()
            
            # è¯»å–è§†é¢‘ä¿¡æ¯
            import json
            video_info_file = self.raw_dir / "video_info.json"
            if video_info_file.exists():
                with open(video_info_file, 'r', encoding='utf-8') as f:
                    video_info = json.load(f)
        except Exception as e:
            logger.warning(f"è¯»å–éƒ¨åˆ†æ–‡ä»¶å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        
        # è°ƒç”¨AIç”Ÿæˆè¯¦ç»†åˆ†æ
        ai_summary = self._generate_ai_summary(dna_content, framework_content, edit_report, final_story)
        
        # å¦‚æœAIåˆ†æå¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°åˆ†æ
        if not ai_summary:
            logger.warning("âš ï¸ AIåˆ†æå¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°åˆ†æ")
            dna_analysis = self._extract_dna_summary(dna_content)
            framework_summary = self._extract_framework_summary(framework_content)
        else:
            # ä½¿ç”¨AIåˆ†æç»“æœ
            dna_analysis = self._format_ai_dna_analysis(ai_summary)
            framework_summary = self._format_ai_framework_summary(ai_summary)
        
        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        report = f"""
# YouTubeæ•…äº‹åˆ›ä½œè¯¦ç»†æŠ¥å‘Š

åˆ›å»ºæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“Œ åŸºæœ¬ä¿¡æ¯
- **è§†é¢‘ID**ï¼š{self.video_id}
- **åˆ›ä½œè€…**ï¼š{self.creator_name}
- **åŸè§†é¢‘æ ‡é¢˜**ï¼š{video_info.get('title', 'N/A')}
- **é¢‘é“åç§°**ï¼š{video_info.get('channel_title', 'N/A')}
- **ç›®æ ‡é•¿åº¦**ï¼š{self.target_length}å­—ï¼ˆçº¦30åˆ†é’Ÿæœ—è¯»ï¼‰
- **ç‰‡æ®µæ•°é‡**ï¼š{self.num_segments}ä¸ª

## ğŸ“– åŸå§‹æ•…äº‹åˆ†æ

### åŸæ–‡æ¦‚å†µ
- **åŸæ–‡é•¿åº¦**ï¼š{len(original_story)}å­—
- **åŸæ–‡å‰100å­—é¢„è§ˆ**ï¼š
  > {original_story[:100] if original_story else 'N/A'}...

### æ•…äº‹DNAæå–ï¼ˆæ ¸å¿ƒè¦ç´ ï¼‰
{dna_analysis}

## ğŸ¯ æ”¹ç¼–ç­–ç•¥ä¸æ¡†æ¶

### æ”¹ç¼–ç›®æ ‡
- **ç›®æ ‡å—ä¼—**ï¼š{framework_summary.get('target_audience', 'N/A')}
- **æ”¹ç¼–ç­–ç•¥**ï¼š{framework_summary.get('adaptation_strategy', 'N/A')}

### 30ç‰‡æ®µæ¡†æ¶ç»“æ„
{framework_summary.get('structure', 'N/A')}

### å…³é”®æ”¹ç¼–ç‚¹
{framework_summary.get('key_adaptations', 'N/A')}

### å¼€åœºé’©å­è®¾è®¡
{framework_summary.get('opening_hook', 'N/A')}

## ğŸ“ æœ€ç»ˆæ•…äº‹æ¦‚è§ˆ

### æˆå“ç»Ÿè®¡
- **æœ€ç»ˆé•¿åº¦**ï¼š{len(final_story)}å­—
- **å®é™…ç‰‡æ®µæ•°**ï¼š30ä¸ª
- **å¹³å‡æ¯ç‰‡æ®µ**ï¼š{len(final_story)//30 if final_story else 0}å­—

### æ•…äº‹å¼€å¤´ï¼ˆå‰200å­—ï¼‰
```
{final_story[:200] if final_story else 'N/A'}...
```

### æ•…äº‹ç»“å°¾ï¼ˆå200å­—ï¼‰
```
...{final_story[-200:] if final_story else 'N/A'}
```

## ğŸ”„ æ”¹ç¼–å¯¹æ¯”åˆ†æ

### ä¸»è¦æ”¹è¿›
1. **å™äº‹ç»“æ„**ï¼šä»åŸå§‹çš„çº¿æ€§å™äº‹æ”¹ä¸º30ç‰‡æ®µçš„èµ·æ‰¿è½¬åˆç»“æ„
2. **æƒ…æ„Ÿæ›²çº¿**ï¼šå¢å¼ºäº†æƒ…æ„Ÿèµ·ä¼ï¼Œæ¯2-3åˆ†é’Ÿè®¾ç½®ä¸€ä¸ªå°é«˜æ½®
3. **äººç‰©å¡‘é€ **ï¼šæ·±åŒ–äº†ä¸»è¦è§’è‰²çš„æ€§æ ¼æå†™å’Œå†…å¿ƒæ´»åŠ¨
4. **åœºæ™¯æå†™**ï¼šå¢åŠ äº†æ›´å¤šæ„Ÿå®˜ç»†èŠ‚å’Œæ°›å›´è¥é€ 
5. **å¯¹è¯ä¼˜åŒ–**ï¼šä½¿å¯¹è¯æ›´åŠ è‡ªç„¶ç”ŸåŠ¨ï¼Œç¬¦åˆäººç‰©æ€§æ ¼

### åˆ›æ–°äº®ç‚¹
{framework_summary.get('innovations', 'N/A')}

## ğŸ“Š è´¨é‡è¯„ä¼°

### ç¼–è¾‘æ¶¦è‰²æŠ¥å‘Š
{edit_report[:500] if edit_report else 'N/A'}

### æ•´ä½“è¯„ä»·
- **æ•…äº‹å®Œæ•´æ€§**ï¼šâœ… å®Œæ•´çš„æ•…äº‹å¼§çº¿ï¼ŒåŒ…å«å¼€ç«¯ã€å‘å±•ã€é«˜æ½®ã€ç»“å±€
- **èŠ‚å¥æ§åˆ¶**ï¼šâœ… 30ä¸ªç‰‡æ®µèŠ‚å¥åˆ†æ˜ï¼Œå¼ å¼›æœ‰åº¦
- **æƒ…æ„Ÿå…±é¸£**ï¼šâœ… å¼ºåŒ–äº†æ™®ä¸–æƒ…æ„Ÿä¸»é¢˜ï¼Œæ˜“å¼•å‘å…±é¸£
- **YouTubeé€‚é…**ï¼šâœ… é€‚åˆ30åˆ†é’Ÿæœ—è¯»ï¼Œæœ‰æ˜ç¡®çš„è®¨è®ºç‚¹

## ğŸ¬ YouTubeå‘å¸ƒå»ºè®®

### è§†é¢‘æ ‡é¢˜å€™é€‰
1. {framework_summary.get('title_1', '[æ ¹æ®æ•…äº‹å†…å®¹ç”Ÿæˆå¸å¼•äººçš„æ ‡é¢˜]')}
2. {framework_summary.get('title_2', '[ç¬¬äºŒä¸ªå¤‡é€‰æ ‡é¢˜]')}
3. {framework_summary.get('title_3', '[ç¬¬ä¸‰ä¸ªå¤‡é€‰æ ‡é¢˜]')}

### ç¼©ç•¥å›¾è¦ç´ 
- **è§†è§‰ç„¦ç‚¹**ï¼š{framework_summary.get('thumbnail_visual', 'ä¸»è§’çš„æƒ…æ„Ÿçˆ†å‘æ—¶åˆ»')}
- **æ–‡å­—å åŠ **ï¼š{framework_summary.get('thumbnail_text', 'éœ‡æ’¼æ€§æ ‡é¢˜æ–‡å­—')}
- **è‰²å½©æ–¹æ¡ˆ**ï¼š{framework_summary.get('thumbnail_color', 'é«˜å¯¹æ¯”åº¦çš„æƒ…æ„Ÿè‰²å½©')}

### è§†é¢‘æè¿°å…³é”®è¯
{framework_summary.get('keywords', '#æ•…äº‹ #æƒ…æ„Ÿ #åŠ±å¿—')}

## ğŸ“ è¾“å‡ºæ–‡ä»¶æ¸…å•

### åŸå§‹æ•°æ®
- `raw/video_info.json` - è§†é¢‘å…ƒä¿¡æ¯
- `raw/comments.json` - çƒ­é—¨è¯„è®º
- `raw/subtitle.txt` - åŸå§‹å­—å¹•/æ•…äº‹

### å¤„ç†è¿‡ç¨‹
- `processing/1_story_dna.txt` - æ•…äº‹DNAåˆ†æ
- `processing/2_framework.txt` - 30ç‰‡æ®µæ¡†æ¶
- `processing/3_draft.txt` - æ‹¼æ¥è‰ç¨¿
- `processing/4_polished.txt` - æ¶¦è‰²ç‰ˆæœ¬

### ç‰‡æ®µæ–‡ä»¶
- `segments/segment_01.txt` è‡³ `segments/segment_30.txt`

### æœ€ç»ˆæˆå“
- `final/story.txt` - æœ€ç»ˆæ•…äº‹ï¼ˆè‹±æ–‡ï¼‰
- `final/edit_report.txt` - ç¼–è¾‘æŠ¥å‘Š
- `final/report.md` - æœ¬æŠ¥å‘Šæ–‡ä»¶

## ğŸš€ åç»­ä¼˜åŒ–å»ºè®®

1. **é…éŸ³åˆ¶ä½œ**ï¼šå»ºè®®ä½¿ç”¨AIè¯­éŸ³åˆæˆï¼Œé€‰æ‹©å¯Œæœ‰æ„Ÿæƒ…çš„å£°éŸ³
2. **èƒŒæ™¯éŸ³ä¹**ï¼šæ ¹æ®æƒ…æ„Ÿæ›²çº¿é€‰æ‹©åˆé€‚çš„èƒŒæ™¯éŸ³ä¹
3. **è§†è§‰ç´ æ**ï¼šå¯æ ¹æ®å…³é”®åœºæ™¯ç”ŸæˆAIæ’å›¾
4. **äº’åŠ¨è®¾è®¡**ï¼šåœ¨è§†é¢‘ä¸­è®¾ç½®äº’åŠ¨é—®é¢˜ï¼Œå¼•å¯¼è§‚ä¼—è¯„è®º
5. **ç³»åˆ—è§„åˆ’**ï¼šå¦‚æœæ•ˆæœå¥½ï¼Œå¯ä»¥åˆ¶ä½œåŒç±»å‹çš„ç³»åˆ—è§†é¢‘

---

*æŠ¥å‘Šç”Ÿæˆå®Œæ¯• - YouTube Story Creator V2*
"""
        
        # ä¿å­˜æŠ¥å‘Š
        with open(self.final_dir / "report.md", 'w', encoding='utf-8') as f:
            f.write(report)
        
        logger.info(f"âœ… è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {self.final_dir / 'report.md'}")
    
    def _extract_dna_summary(self, dna_content: str) -> str:
        """ä»DNAå†…å®¹ä¸­æå–ä¸­æ–‡æ€»ç»“"""
        if not dna_content:
            return "N/A"
        
        summary = {}
        
        # æå–å…³é”®ä¿¡æ¯
        if "Story Type" in dna_content:
            import re
            type_match = re.search(r"Story Type\n(.+?)\n", dna_content)
            if type_match:
                summary['story_type'] = type_match.group(1)
        
        if "Core Theme" in dna_content:
            theme_match = re.search(r"Core Theme\n(.+?)\n", dna_content)
            if theme_match:
                summary['core_theme'] = theme_match.group(1)
        
        # æ„å»ºä¸­æ–‡æ€»ç»“
        result = f"""
- **æ•…äº‹ç±»å‹**ï¼š{summary.get('story_type', 'N/A')}
- **æ ¸å¿ƒä¸»é¢˜**ï¼š{summary.get('core_theme', 'N/A')}
- **ä¸»è¦è§’è‰²**ï¼šä»åŸå§‹å†…å®¹ä¸­æå–å¹¶æ·±åŒ–çš„è§’è‰²è®¾å®š
- **æƒ…æ„Ÿå†…æ ¸**ï¼šé€šè¿‡AIåˆ†æè¯†åˆ«çš„æƒ…æ„Ÿé©±åŠ¨åŠ›
- **å†²çªè®¾ç½®**ï¼šå†…å¤–å†²çªçš„åŒé‡è®¾è®¡"""
        
        return result
    
    def _extract_framework_summary(self, framework_content: str) -> Dict[str, Any]:
        """ä»æ¡†æ¶å†…å®¹ä¸­æå–å…³é”®ä¿¡æ¯"""
        summary = {}
        
        if not framework_content:
            return summary
        
        # æå–ç›®æ ‡å—ä¼—
        if "Target Audience" in framework_content:
            import re
            audience_match = re.search(r"Target Audience: (.+?)\n", framework_content)
            if audience_match:
                summary['target_audience'] = audience_match.group(1)
        
        # æå–æ”¹ç¼–ç­–ç•¥
        if "Adaptation Strategy" in framework_content:
            strategy_match = re.search(r"Adaptation Strategy: (.+?)\n", framework_content)
            if strategy_match:
                summary['adaptation_strategy'] = strategy_match.group(1)
        
        # æå–ç« èŠ‚ç»“æ„
        chapters = []
        if "Chapter One" in framework_content:
            chapters.append("ç¬¬ä¸€ç« ï¼šå¼€ç«¯ï¼ˆç‰‡æ®µ1-4ï¼‰- å»ºç«‹ä¸–ç•Œè§‚å’Œä¸»è§’")
        if "Chapter Two" in framework_content:
            chapters.append("ç¬¬äºŒç« ï¼šå‘å±•ï¼ˆç‰‡æ®µ5-13ï¼‰- æ·±åŒ–å†²çªå’Œå…³ç³»")
        if "Chapter Three" in framework_content:
            chapters.append("ç¬¬ä¸‰ç« ï¼šå†²çªå‡çº§ï¼ˆç‰‡æ®µ14-19ï¼‰- æ¨å‘é«˜æ½®")
        if "Chapter Four" in framework_content:
            chapters.append("ç¬¬å››ç« ï¼šé«˜æ½®ï¼ˆç‰‡æ®µ20-26ï¼‰- å†³æˆ˜æ—¶åˆ»")
        if "Chapter Five" in framework_content:
            chapters.append("ç¬¬äº”ç« ï¼šç»“å±€ï¼ˆç‰‡æ®µ27-30ï¼‰- æ”¶æŸä¸å‡å")
        
        summary['structure'] = "\n".join([f"{i+1}. {ch}" for i, ch in enumerate(chapters)])
        
        # æå–å¼€åœºé’©å­
        if "Segment 1:" in framework_content:
            hook_match = re.search(r"Segment 1: (.+?) \(\d+ words\)\n- Content: (.+?)\n", framework_content)
            if hook_match:
                summary['opening_hook'] = f"""
- **é’©å­ç±»å‹**ï¼š{hook_match.group(1)}
- **è®¾è®¡ç†å¿µ**ï¼šåœ¨å‰100å­—å†…ç«‹å³åˆ›é€ æ‚¬å¿µæˆ–å†²çª
- **å…·ä½“å†…å®¹**ï¼š{hook_match.group(2)}
- **é¢„æœŸæ•ˆæœ**ï¼šç¬é—´æŠ“ä½è§‚ä¼—æ³¨æ„åŠ›ï¼Œäº§ç”Ÿç»§ç»­è§‚çœ‹çš„æ¬²æœ›"""
        
        # æå–å…³é”®æ”¹ç¼–ç‚¹
        summary['key_adaptations'] = """
1. **ç»“æ„é‡ç»„**ï¼šå°†åŸå§‹å†…å®¹é‡æ–°ç»„ç»‡ä¸º30ä¸ªç²¾å¿ƒè®¾è®¡çš„ç‰‡æ®µ
2. **èŠ‚å¥ä¼˜åŒ–**ï¼šç¡®ä¿æ¯ä¸ªç‰‡æ®µéƒ½æœ‰æ˜ç¡®çš„ç„¦ç‚¹å’Œæ¨è¿›ä½œç”¨
3. **æƒ…æ„Ÿå¢å¼º**ï¼šåœ¨å…³é”®æ—¶åˆ»åŠ å…¥æ›´å¤šå†…å¿ƒç‹¬ç™½å’Œæ„Ÿå®˜æå†™
4. **æ‚¬å¿µè®¾ç½®**ï¼šæ¯ä¸ªç‰‡æ®µç»“å°¾éƒ½é¢„ç•™é’©å­ï¼Œå¼•å¯¼ç»§ç»­é˜…è¯»
5. **é«˜æ½®æ‰“é€ **ï¼šç¬¬20-26ç‰‡æ®µé›†ä¸­çˆ†å‘ï¼Œæƒ…æ„Ÿè¾¾åˆ°é¡¶å³°"""
        
        # åˆ›æ–°äº®ç‚¹
        summary['innovations'] = """
- é‡‡ç”¨**æ··åˆè§†è§’å™äº‹**ï¼Œå¢å¼ºä»£å…¥æ„Ÿ
- è®¾ç½®**å¤šé‡åè½¬**ï¼Œä¿æŒæ•…äº‹æ–°é²œæ„Ÿ
- åŠ å…¥**å½“ä»£å…ƒç´ **ï¼Œæé«˜æ•…äº‹ç›¸å…³æ€§
- å¼ºåŒ–**æƒ…æ„Ÿå…±é¸£ç‚¹**ï¼Œä¾¿äºè§‚ä¼—åˆ†äº«ä¼ æ’­"""
        
        # YouTubeç›¸å…³
        summary['title_1'] = "[éœ‡æ’¼] ä½ ç»å¯¹æƒ³ä¸åˆ°çš„ç»“å±€ï¼30åˆ†é’Ÿæ”¹å˜äººç”Ÿçš„æ•…äº‹"
        summary['title_2'] = "ä»å¹³å‡¡åˆ°éå‡¡ï¼šä¸€ä¸ªçœŸå®æ•…äº‹çš„30ä¸ªè½¬æŠ˜ç‚¹"
        summary['title_3'] = "å¿…çœ‹ï¼è¿™ä¸ªæ•…äº‹ä¼šè®©ä½ é‡æ–°æ€è€ƒäººç”Ÿçš„æ„ä¹‰"
        
        summary['thumbnail_visual'] = "ä¸»è§’åœ¨å…³é”®æ—¶åˆ»çš„æƒ…æ„Ÿçˆ†å‘ç‰¹å†™"
        summary['thumbnail_text'] = "æ”¹å˜ä¸€ç”Ÿçš„30åˆ†é’Ÿ"
        summary['thumbnail_color'] = "æš–è‰²è°ƒä¸å†·è‰²è°ƒçš„å¼ºçƒˆå¯¹æ¯”"
        
        summary['keywords'] = "#åŠ±å¿—æ•…äº‹ #äººç”Ÿæ„Ÿæ‚Ÿ #æƒ…æ„Ÿæ•…äº‹ #30åˆ†é’Ÿæ•…äº‹ #çœŸå®æ”¹ç¼– #æ³ªç‚¹æ»¡æ»¡ #æ­£èƒ½é‡"
        
        return summary
    
    def _generate_ai_summary(self, dna_content: str, framework_content: str, 
                            edit_report: str, final_story: str) -> Optional[Dict[str, Any]]:
        """è°ƒç”¨AIç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Š
        
        Args:
            dna_content: DNAåˆ†æå†…å®¹
            framework_content: æ¡†æ¶å†…å®¹
            edit_report: ç¼–è¾‘æŠ¥å‘Š
            final_story: æœ€ç»ˆæ•…äº‹ï¼ˆå‰1000å­—ç”¨äºæå–äººç‰©ç‰¹å¾ï¼‰
            
        Returns:
            AIç”Ÿæˆçš„JSONæ ¼å¼åˆ†æç»“æœï¼Œå¤±è´¥è¿”å›None
        """
        try:
            logger.info("ğŸ¤– è°ƒç”¨AIç”Ÿæˆè¯¦ç»†åˆ†ææŠ¥å‘Š...")
            
            # è¯»å–æŠ¥å‘Šç”Ÿæˆæç¤ºè¯
            prompt_file = Path(__file__).parent.parent / "prompts" / "report_generator.md"
            if not prompt_file.exists():
                logger.error(f"æ‰¾ä¸åˆ°æŠ¥å‘Šç”Ÿæˆæç¤ºè¯: {prompt_file}")
                return None
            
            with open(prompt_file, 'r', encoding='utf-8') as f:
                system_prompt = f.read()
            
            # æ„å»ºè¾“å…¥å†…å®¹
            input_content = f"""
==================================================
Story DNA
==================================================
{dna_content if dna_content else 'N/A'}

==================================================
Adaptation Framework
==================================================
{framework_content if framework_content else 'N/A'}

==================================================
Editorial Report
==================================================
{edit_report if edit_report else 'N/A'}

==================================================
Final Story Sample
==================================================
{final_story[:1000] if final_story else 'N/A'}
"""
            
            # DEBUG: è®°å½•å®Œæ•´è¾“å…¥
            logger.debug("=" * 80)
            logger.debug("[DEBUG] _generate_ai_summary - AIè°ƒç”¨è¾“å…¥:")
            logger.debug(f"system_prompté•¿åº¦: {len(system_prompt)} å­—ç¬¦")
            logger.debug("å®Œæ•´system_prompt:")
            logger.debug(system_prompt)
            logger.debug(f"input_contenté•¿åº¦: {len(input_content)} å­—ç¬¦")
            logger.debug("å®Œæ•´input_content:")
            logger.debug(input_content)
            logger.debug("=" * 80)
            
            # è°ƒç”¨Gemini API
            response = self.gemini_client.analyze_text(
                text=input_content,
                prompt=system_prompt
            )
            
            # DEBUG: è®°å½•å®Œæ•´è¾“å‡º
            logger.debug("=" * 80)
            logger.debug("[DEBUG] _generate_ai_summary - AIè°ƒç”¨è¾“å‡º:")
            logger.debug(f"è¾“å‡ºé•¿åº¦: {len(response) if response else 0} å­—ç¬¦")
            if response:
                logger.debug("å®Œæ•´è¾“å‡ºå†…å®¹:")
                logger.debug(response)
            else:
                logger.debug("å“åº”ä¸ºç©º")
            logger.debug("=" * 80)
            
            if not response:
                logger.error("AIåˆ†æè¿”å›ç©ºç»“æœ")
                return None
            
            # æå–JSONéƒ¨åˆ†
            import json
            import re
            
            # æŸ¥æ‰¾JSONä»£ç å—
            json_match = re.search(r'```json\s*\n(.+?)\n```', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # å°è¯•ç›´æ¥è§£ææ•´ä¸ªå“åº”
                json_str = response
            
            # è§£æJSON
            try:
                result = json.loads(json_str)
                logger.info("âœ… AIåˆ†ææŠ¥å‘Šç”ŸæˆæˆåŠŸ")
                
                # ä¿å­˜AIåˆ†æç»“æœ
                ai_report_file = self.final_dir / "ai_analysis.json"
                with open(ai_report_file, 'w', encoding='utf-8') as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
                logger.info(f"ğŸ’¾ AIåˆ†æç»“æœå·²ä¿å­˜: {ai_report_file}")
                
                return result
            except json.JSONDecodeError as e:
                logger.error(f"JSONè§£æå¤±è´¥: {e}")
                logger.debug(f"åŸå§‹å“åº”: {response[:500]}...")
                import traceback
                traceback.print_exc()
                return None
                
        except Exception as e:
            logger.error(f"AIåˆ†æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _format_ai_dna_analysis(self, ai_summary: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–AIç”Ÿæˆçš„DNAåˆ†æç»“æœ
        
        Args:
            ai_summary: AIç”Ÿæˆçš„åˆ†æç»“æœ
            
        Returns:
            æ ¼å¼åŒ–çš„ä¸­æ–‡DNAåˆ†ææ–‡æœ¬
        """
        try:
            story_analysis = ai_summary.get('story_analysis', {})
            
            # æå–å…³é”®ä¿¡æ¯
            original_type = story_analysis.get('original_type', 'N/A')
            original_theme = story_analysis.get('original_theme', 'N/A')
            adaptation_strategy = story_analysis.get('adaptation_strategy', 'N/A')
            key_improvements = story_analysis.get('key_improvements', [])
            
            # æ„å»ºæ ¼å¼åŒ–æ–‡æœ¬
            result = f"""
- **æ•…äº‹ç±»å‹**ï¼š{original_type}
- **æ ¸å¿ƒä¸»é¢˜**ï¼š{original_theme}
- **æ”¹ç¼–ç­–ç•¥**ï¼š{adaptation_strategy}

### å…³é”®æ”¹è¿›ç‚¹
"""
            
            for i, improvement in enumerate(key_improvements, 1):
                result += f"{i}. {improvement}\n"
            
            # æ·»åŠ äººç‰©åˆ†æï¼ˆå¦‚æœæœ‰ï¼‰
            character_profiles = ai_summary.get('character_profiles', [])
            if character_profiles:
                result += "\n### ä¸»è¦è§’è‰²åˆ†æ\n"
                for char in character_profiles[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªä¸»è¦è§’è‰²
                    result += f"\n**{char.get('chinese_name', char.get('name', 'N/A'))}**"
                    result += f" ({char.get('role', '')})"
                    result += f"\n- æ€§æ ¼ï¼š{char.get('personality', 'N/A')}"
                    physical = char.get('physical_features', {})
                    if physical:
                        result += f"\n- å¤–è²Œï¼š{physical.get('age', '')}ï¼Œ{physical.get('build', '')}ï¼Œ{physical.get('hair', '')}"
                    result += "\n"
            
            return result
            
        except Exception as e:
            logger.error(f"æ ¼å¼åŒ–AI DNAåˆ†æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            # è¿”å›åŸºç¡€åˆ†æ
            return self._extract_dna_summary('')
    
    def _format_ai_framework_summary(self, ai_summary: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¼å¼åŒ–AIç”Ÿæˆçš„æ¡†æ¶åˆ†æç»“æœ
        
        Args:
            ai_summary: AIç”Ÿæˆçš„åˆ†æç»“æœ
            
        Returns:
            æ ¼å¼åŒ–çš„æ¡†æ¶åˆ†æå­—å…¸
        """
        try:
            summary = {}
            
            # ä»AIåˆ†æä¸­æå–ä¿¡æ¯
            story_analysis = ai_summary.get('story_analysis', {})
            opening_hook = ai_summary.get('opening_hook', {})
            climax_analysis = ai_summary.get('climax_analysis', {})
            youtube_strategy = ai_summary.get('youtube_strategy', {})
            production_guide = ai_summary.get('production_guide', {})
            
            # ç›®æ ‡å—ä¼—å’Œç­–ç•¥
            summary['target_audience'] = youtube_strategy.get('target_audience', 'å¹´è½»æˆå¹´äººï¼ˆ18-35å²ï¼‰ï¼Œå¯¹æƒ…æ„Ÿæ•…äº‹æ„Ÿå…´è¶£')
            summary['adaptation_strategy'] = story_analysis.get('adaptation_strategy', 'å°†çº¿æ€§å™äº‹è½¬æ¢ä¸ºæˆå‰§æ€§å¼§çº¿ç»“æ„')
            
            # ç« èŠ‚ç»“æ„
            structure = f"""
- **ç¬¬ä¸€ç« ï¼šå¼€ç«¯**ï¼ˆç‰‡æ®µ1-4ï¼‰- å»ºç«‹ä¸–ç•Œè§‚å’Œä¸»è§’
- **ç¬¬äºŒç« ï¼šå‘å±•**ï¼ˆç‰‡æ®µ5-13ï¼‰- æ·±åŒ–å†²çªå’Œå…³ç³»
- **ç¬¬ä¸‰ç« ï¼šå†²çªå‡çº§**ï¼ˆç‰‡æ®µ14-19ï¼‰- æ¨å‘é«˜æ½®
- **ç¬¬å››ç« ï¼šé«˜æ½®**ï¼ˆç‰‡æ®µ20-26ï¼‰- {climax_analysis.get('emotional_peak', 'å†³æˆ˜æ—¶åˆ»')}
- **ç¬¬äº”ç« ï¼šç»“å±€**ï¼ˆç‰‡æ®µ27-30ï¼‰- {climax_analysis.get('resolution', 'æƒ…æ„Ÿå‡åä¸ä¸»é¢˜å›å½’')}
"""
            summary['structure'] = structure
            
            # å¼€åœºé’©å­
            hook_info = f"""
- **é’©å­ç±»å‹**ï¼š{opening_hook.get('type', 'Opening Hook')}
- **å…·ä½“å†…å®¹**ï¼š{opening_hook.get('content', 'N/A')}
- **é¢„æœŸæ•ˆæœ**ï¼š{opening_hook.get('effectiveness', 'ç¬é—´æŠ“ä½è§‚ä¼—æ³¨æ„åŠ›')}
- **ç¬¬ä¸€å¥è¯**ï¼š{opening_hook.get('first_line', 'N/A')}
"""
            summary['opening_hook'] = hook_info
            
            # å…³é”®æ”¹ç¼–ç‚¹
            key_improvements = story_analysis.get('key_improvements', [])
            adaptations = "\n".join([f"{i+1}. {imp}" for i, imp in enumerate(key_improvements)])
            summary['key_adaptations'] = adaptations if adaptations else "1. ç»“æ„é‡ç»„\n2. èŠ‚å¥ä¼˜åŒ–\n3. æƒ…æ„Ÿå¢å¼º"
            
            # YouTubeæ ‡é¢˜
            titles = youtube_strategy.get('titles', [])
            if titles:
                summary['title_1'] = titles[0].get('title', '[éœ‡æ’¼] 30åˆ†é’Ÿæ”¹å˜äººç”Ÿçš„æ•…äº‹')
                summary['title_2'] = titles[1].get('title', 'ä¸€ä¸ªçœŸå®æ•…äº‹çš„30ä¸ªè½¬æŠ˜ç‚¹') if len(titles) > 1 else 'å¿…çœ‹æ•…äº‹'
                summary['title_3'] = titles[2].get('title', 'è¿™ä¸ªæ•…äº‹ä¼šè®©ä½ é‡æ–°æ€è€ƒ') if len(titles) > 2 else 'æ„Ÿäººæ•…äº‹'
            else:
                summary['title_1'] = "[éœ‡æ’¼] 30åˆ†é’Ÿæ”¹å˜äººç”Ÿçš„æ•…äº‹"
                summary['title_2'] = "ä¸€ä¸ªçœŸå®æ•…äº‹çš„30ä¸ªè½¬æŠ˜ç‚¹"
                summary['title_3'] = "è¿™ä¸ªæ•…äº‹ä¼šè®©ä½ é‡æ–°æ€è€ƒäººç”Ÿ"
            
            # ç¼©ç•¥å›¾è®¾è®¡
            thumbnail = youtube_strategy.get('thumbnail', {})
            summary['thumbnail_visual'] = thumbnail.get('main_element', 'ä¸»è§’æƒ…æ„Ÿçˆ†å‘ç‰¹å†™')
            summary['thumbnail_text'] = thumbnail.get('text_overlay', 'æ”¹å˜ä¸€ç”Ÿçš„30åˆ†é’Ÿ')
            summary['thumbnail_color'] = thumbnail.get('color_scheme', 'æš–å†·è‰²å¯¹æ¯”')
            
            # æ ‡ç­¾å’Œå…³é”®è¯
            tags = youtube_strategy.get('tags', [])
            summary['keywords'] = ' '.join(tags) if tags else "#åŠ±å¿—æ•…äº‹ #æƒ…æ„Ÿæ•…äº‹ #30åˆ†é’Ÿæ•…äº‹"
            
            # åˆ¶ä½œå»ºè®®
            summary['voice_style'] = production_guide.get('voice_style', 'å¯Œæœ‰æ„Ÿæƒ…çš„å™è¿°é£æ ¼')
            summary['bgm_suggestion'] = production_guide.get('bgm_suggestion', 'æ¸è¿›å¼æƒ…æ„ŸéŸ³ä¹')
            summary['pacing'] = production_guide.get('pacing', '2-3åˆ†é’Ÿä¸€ä¸ªå°é«˜æ½®')
            
            # è´¨é‡è¯„åˆ†
            quality = ai_summary.get('quality_metrics', {})
            summary['quality_score'] = f"""
- æ•…äº‹è¿è´¯æ€§ï¼š{quality.get('story_coherence', 90)}%
- æƒ…æ„Ÿå†²å‡»åŠ›ï¼š{quality.get('emotional_impact', 85)}%
- èŠ‚å¥è´¨é‡ï¼š{quality.get('pacing_quality', 88)}%
- YouTubeé€‚é…åº¦ï¼š{quality.get('youtube_readiness', 92)}%
"""
            
            # ç³»åˆ—æ½œåŠ›
            series = ai_summary.get('series_potential', {})
            if series.get('feasibility') == 'é«˜':
                summary['series_suggestion'] = f"å»ºè®®åˆ¶ä½œ{series.get('suggested_episodes', 5)}é›†ç³»åˆ—"
            
            return summary
            
        except Exception as e:
            logger.error(f"æ ¼å¼åŒ–AIæ¡†æ¶åˆ†æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            # è¿”å›åŸºç¡€åˆ†æ
            return self._extract_framework_summary('')
    
    def generate_image_prompts_v2(self) -> bool:
        """
        ä¼˜åŒ–ç‰ˆSDå›¾ç‰‡æç¤ºè¯ç”Ÿæˆ
        ä½¿ç”¨æ–°çš„ç‹¬ç«‹æ¨¡å— ImagePromptGenerator
        
        Returns:
            bool: æˆåŠŸè¿”å›trueï¼Œå¤±è´¥è¿”å›false
        """
        try:
            logger.info(f"ğŸ¨ å¼€å§‹ç”ŸæˆSDå›¾ç‰‡æç¤ºè¯ï¼ˆä½¿ç”¨æ–°æ¨¡å—ï¼Œæ¯ç‰‡æ®µ{self.images_per_segment}å¼ ï¼‰...")
            
            # ä½¿ç”¨æ–°çš„ImagePromptGeneratoræ¨¡å—
            generator = ImagePromptGenerator(
                creator_name=self.creator_name,
                video_id=self.video_id,
                sd_prompt_file=self.sd_prompt_file,
                images_per_segment=self.images_per_segment
            )
            
            # ç”Ÿæˆæ‰€æœ‰ç‰‡æ®µçš„æç¤ºè¯
            results = generator.generate_for_segments()
            
            # ä¿å­˜ç»“æœ
            generator.save_results(results)
            
            # ç»Ÿè®¡ä¿¡æ¯
            total_prompts = results.get("total_prompts", 0)
            total_segments = results.get("total_segments", 0)
            
            if total_prompts > 0:
                logger.info(f"âœ… æˆåŠŸå¤„ç† {total_segments} ä¸ªç‰‡æ®µï¼Œç”Ÿæˆ {total_prompts} ä¸ªSDæç¤ºè¯")
                logger.info(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {generator.final_dir}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
                if "segments" in results:
                    errors = [k for k, v in results["segments"].items() if "error" in v]
                    if errors:
                        logger.warning(f"âš ï¸ {len(errors)} ä¸ªç‰‡æ®µå¤„ç†å¤±è´¥: {errors}")
                
                return True
            else:
                logger.warning("æ²¡æœ‰ç”Ÿæˆä»»ä½•æç¤ºè¯")
                return False
                
        except Exception as e:
            logger.error(f"ç”ŸæˆSDæç¤ºè¯å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def extract_character_profiles(self, framework: str) -> dict:
        """
        ä»æ¡†æ¶ä¸­æå–è§’è‰²ç‰¹å¾æè¿°
        
        Args:
            framework: æ¡†æ¶æ–‡æœ¬
            
        Returns:
            è§’è‰²ç‰¹å¾å­—å…¸
        """
        import re
        
        characters = {}
        
        # å°è¯•å¤šç§æ¨¡å¼åŒ¹é…è§’è‰²æè¿°
        patterns = [
            r"è§’è‰²\d+ï¼š\[([^\]]+)\][^*]*\*\*[^*]*\*\*([^*]+)",  # è§’è‰²1ï¼š[åå­—]...æè¿°
            r"Character \d+:?\s*([^\n]+)[^*]*physical[^:]*:([^*\n]+)",  # Character 1: Name...physical:
            r"ä¸»è§’[^:ï¼š]*[:ï¼š]\s*([^\n,ï¼Œ]+)[^*]*å¤–[è²Œè§‚][^:ï¼š]*[:ï¼š]([^*\n]+)",  # ä¸»è§’ï¼šåå­—...å¤–è²Œï¼š
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, framework, re.IGNORECASE | re.DOTALL)
            for match in matches:
                if len(match) >= 2:
                    name = match[0].strip()
                    description = match[1].strip()
                    characters[name] = {
                        "name": name,
                        "visual_description": description,
                        "sd_features": self.extract_sd_features(description)
                    }
        
        # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤è§’è‰²
        if not characters:
            characters["ä¸»è§’"] = {
                "name": "ä¸»è§’",
                "visual_description": "å¹´è½»äººï¼Œåšå®šçš„çœ¼ç¥",
                "sd_features": "young adult, determined eyes, casual clothing"
            }
        
        return characters
    
    def extract_sd_features(self, description: str) -> str:
        """
        ä»ä¸­æ–‡æè¿°æå–SDå‹å¥½çš„ç‰¹å¾
        
        Args:
            description: ä¸­æ–‡æè¿°
            
        Returns:
            SDç‰¹å¾æè¿°
        """
        # ç®€å•çš„ç‰¹å¾æå–ï¼ˆå®é™…å¯ä»¥ç”¨AIç¿»è¯‘ï¼‰
        features = []
        
        # å¹´é¾„ç‰¹å¾
        if "å¹´è½»" in description or "é’å¹´" in description:
            features.append("young adult")
        elif "ä¸­å¹´" in description:
            features.append("middle-aged")
        elif "è€" in description:
            features.append("elderly")
        
        # æ€§åˆ«ç‰¹å¾
        if "å¥³" in description:
            features.append("female")
        elif "ç”·" in description:
            features.append("male")
        
        # å…¶ä»–ç‰¹å¾
        if "é•¿å‘" in description:
            features.append("long hair")
        elif "çŸ­å‘" in description:
            features.append("short hair")
        
        return ", ".join(features) if features else "person"
    
    def extract_key_scenes_from_segment(self, segment_content: str, segment_num: int, num_scenes: int) -> list:
        """
        ä»segmentå†…å®¹ä¸­æå–å…³é”®åœºæ™¯
        
        Args:
            segment_content: ç‰‡æ®µå†…å®¹
            segment_num: ç‰‡æ®µç¼–å·
            num_scenes: è¦æå–çš„åœºæ™¯æ•°é‡
            
        Returns:
            å…³é”®åœºæ™¯åˆ—è¡¨
        """
        # ä½¿ç”¨AIæå–å…³é”®åœºæ™¯
        prompt = f"""
ä»ä»¥ä¸‹æ•…äº‹ç‰‡æ®µä¸­æå–{num_scenes}ä¸ªæœ€å…·è§†è§‰å†²å‡»åŠ›çš„å…³é”®åœºæ™¯ï¼Œç”¨äºç”Ÿæˆæ’ç”»ã€‚

ç‰‡æ®µå†…å®¹ï¼š
{segment_content[:2000]}...

è¯·è¿”å›JSONæ ¼å¼ï¼š
[
  {{
    "description": "åœºæ™¯çš„è§†è§‰æè¿°",
    "emotion": "åœºæ™¯çš„æƒ…æ„Ÿæ°›å›´",
    "key_elements": ["å…³é”®å…ƒç´ 1", "å…³é”®å…ƒç´ 2"],
    "color_mood": "è‰²è°ƒæ°›å›´"
  }}
]
"""
        
        try:
            response = self.gemini_client.generate_content(prompt)
            
            # è§£æJSON
            import json
            import re
            
            json_match = re.search(r'\[.*?\]', response, re.DOTALL)
            if json_match:
                scenes = json.loads(json_match.group())
                return scenes[:num_scenes]
        except:
            pass
        
        # å¦‚æœAIæå–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤åœºæ™¯
        return [{
            "description": f"ç‰‡æ®µ{segment_num}çš„å…³é”®æ—¶åˆ»",
            "emotion": "dramatic",
            "key_elements": ["character", "emotion"],
            "color_mood": "moody"
        }]
    
    def generate_sd_prompt_for_scene(self, scene: dict, character_profiles: dict, 
                                     segment_num: int, scene_idx: int) -> str:
        """
        ä¸ºåœºæ™¯ç”ŸæˆSDæç¤ºè¯
        
        Args:
            scene: åœºæ™¯ä¿¡æ¯
            character_profiles: è§’è‰²ç‰¹å¾
            segment_num: ç‰‡æ®µç¼–å·
            scene_idx: åœºæ™¯ç´¢å¼•
            
        Returns:
            SDæç¤ºè¯
        """
        # åŸºç¡€æç¤ºè¯æ¨¡æ¿
        base_prompt = "masterpiece, best quality, ultra-detailed, illustration"
        
        # æ·»åŠ è§’è‰²ç‰¹å¾ï¼ˆä¿æŒä¸€è‡´æ€§ï¼‰
        if character_profiles:
            # å–ç¬¬ä¸€ä¸ªä¸»è¦è§’è‰²
            main_char = list(character_profiles.values())[0]
            char_features = main_char.get("sd_features", "")
            if char_features:
                base_prompt += f", {char_features}"
        
        # æ·»åŠ åœºæ™¯æè¿°
        scene_desc = scene.get("description", "")
        if scene_desc:
            # è¿™é‡Œå¯ä»¥è°ƒç”¨ç¿»è¯‘APIæˆ–ä½¿ç”¨é¢„å®šä¹‰æ˜ å°„
            base_prompt += f", {self.translate_to_sd_style(scene_desc)}"
        
        # æ·»åŠ æƒ…æ„Ÿæ°›å›´
        emotion = scene.get("emotion", "")
        emotion_mapping = {
            "dramatic": "dramatic lighting, intense atmosphere",
            "sad": "melancholic mood, soft lighting",
            "happy": "bright, cheerful atmosphere",
            "tense": "tension, dramatic shadows",
            "peaceful": "serene, calm atmosphere"
        }
        if emotion in emotion_mapping:
            base_prompt += f", {emotion_mapping[emotion]}"
        
        # æ·»åŠ è‰²è°ƒ
        color_mood = scene.get("color_mood", "")
        if color_mood:
            base_prompt += f", {color_mood} color palette"
        
        # æ·»åŠ é£æ ¼æ ‡ç­¾
        base_prompt += ", cinematic composition, emotional storytelling"
        
        # è´Ÿé¢æç¤ºè¯
        negative_prompt = "low quality, blurry, deformed, ugly, bad anatomy"
        
        return {
            "positive": base_prompt,
            "negative": negative_prompt
        }
    
    def translate_to_sd_style(self, chinese_desc: str) -> str:
        """
        å°†ä¸­æ–‡æè¿°ç¿»è¯‘ä¸ºSDé£æ ¼ï¼ˆç®€åŒ–ç‰ˆï¼‰
        
        Args:
            chinese_desc: ä¸­æ–‡æè¿°
            
        Returns:
            SDé£æ ¼æè¿°
        """
        # è¿™é‡Œåº”è¯¥è°ƒç”¨ç¿»è¯‘APIï¼Œç°åœ¨ç”¨ç®€å•æ˜ å°„
        if len(chinese_desc) > 50:
            return "complex scene with multiple elements"
        else:
            return "focused scene"
    
    def save_prompts_as_markdown(self, prompts: list, character_profiles: dict):
        """
        å°†æç¤ºè¯ä¿å­˜ä¸ºMarkdownæ ¼å¼
        
        Args:
            prompts: æç¤ºè¯åˆ—è¡¨
            character_profiles: è§’è‰²ç‰¹å¾
        """
        markdown_file = self.final_dir / "sd_prompts_v2.md"
        with open(markdown_file, 'w', encoding='utf-8') as f:
            f.write("# SDå›¾ç‰‡æç¤ºè¯ï¼ˆä¼˜åŒ–ç‰ˆï¼‰\n\n")
            f.write(f"ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            # è§’è‰²ç‰¹å¾
            f.write("## è§’è‰²ç‰¹å¾\n\n")
            for name, profile in character_profiles.items():
                f.write(f"### {name}\n")
                f.write(f"- è§†è§‰æè¿°ï¼š{profile.get('visual_description', '')}\n")
                f.write(f"- SDç‰¹å¾ï¼š{profile.get('sd_features', '')}\n\n")
            
            # åœºæ™¯æç¤ºè¯
            f.write("## åœºæ™¯æç¤ºè¯\n\n")
            current_segment = 0
            for prompt in prompts:
                if prompt['segment'] != current_segment:
                    current_segment = prompt['segment']
                    f.write(f"\n### ç‰‡æ®µ {current_segment}\n\n")
                
                f.write(f"#### åœºæ™¯ {prompt['scene_index']}\n")
                f.write(f"- **æè¿°**ï¼š{prompt['scene_description']}\n")
                f.write(f"- **æƒ…æ„Ÿ**ï¼š{prompt['emotion']}\n")
                f.write(f"- **æ­£é¢æç¤ºè¯**ï¼š\n```\n{prompt['sd_prompt']['positive']}\n```\n")
                f.write(f"- **è´Ÿé¢æç¤ºè¯**ï¼š\n```\n{prompt['sd_prompt']['negative']}\n```\n\n")
        
        logger.info(f"ğŸ“ Markdownæ ¼å¼æç¤ºè¯å·²ä¿å­˜åˆ°: {markdown_file}")
    
    def generate_image_prompts(self) -> bool:
        """ä¸ºæ¯ä¸ªæ•…äº‹ç‰‡æ®µç”ŸæˆSDå›¾ç‰‡æç¤ºè¯ï¼ˆä¼˜åŒ–ç‰ˆï¼šæ‰¹é‡ç”Ÿæˆï¼‰
        
        Returns:
            bool: æˆåŠŸè¿”å›trueï¼Œå¤±è´¥è¿”å›false
        """
        try:
            logger.info("ğŸ¨ å¼€å§‹ç”ŸæˆSDå›¾ç‰‡æç¤ºè¯ï¼ˆæ‰¹é‡ä¼˜åŒ–ç‰ˆï¼‰...")
            
            # è¯»å–frameworkæ–‡ä»¶
            framework_file = self.processing_dir / "2_framework.txt"
            if not framework_file.exists():
                logger.error(f"Frameworkæ–‡ä»¶ä¸å­˜åœ¨: {framework_file}")
                return False
            
            with open(framework_file, 'r', encoding='utf-8') as f:
                framework_content = f.read()
            
            # ä»frameworkæå–è§’è‰²ä¿¡æ¯
            character_profiles = self._extract_characters_from_framework(framework_content)
            if character_profiles:
                logger.info(f"âœ… ä»Frameworkæå–åˆ°{len(character_profiles)}ä¸ªè§’è‰²ä¿¡æ¯")
            else:
                logger.warning("âš ï¸ æœªèƒ½ä»Frameworkæå–è§’è‰²ä¿¡æ¯")
            
            # ä»frameworkæå–ç‰‡æ®µä¿¡æ¯
            segments_info = self._extract_segments_from_framework(framework_content)
            if not segments_info:
                logger.warning("æœªèƒ½ä»Frameworkæå–ç‰‡æ®µä¿¡æ¯")
                return False
            
            logger.info(f"âœ… ä»Frameworkæå–åˆ°{len(segments_info)}ä¸ªç‰‡æ®µä¿¡æ¯")
            
            # è¯»å–SDæç¤ºè¯ç”Ÿæˆpromptï¼ˆä½¿ç”¨æŒ‡å®šçš„æ–‡ä»¶ï¼‰
            prompt_file = Path(__file__).parent.parent / self.sd_prompt_file
            if not prompt_file.exists():
                logger.error(f"æ‰¾ä¸åˆ°SDæç¤ºè¯ç”Ÿæˆprompt: {prompt_file}")
                # å°è¯•ä½¿ç”¨é»˜è®¤æ–‡ä»¶
                prompt_file = Path(__file__).parent.parent / "prompts" / "sd_image_generator_v2.md"
                if not prompt_file.exists():
                    logger.error("é»˜è®¤promptæ–‡ä»¶ä¹Ÿä¸å­˜åœ¨")
                    return False
                logger.info(f"ä½¿ç”¨é»˜è®¤promptæ–‡ä»¶: {prompt_file}")
            
            with open(prompt_file, 'r', encoding='utf-8') as f:
                system_prompt = f.read()
            
            # ç”Ÿæˆç»“æœå®¹å™¨
            all_prompts = {
                "å°é¢": None,
                "ç‰‡æ®µ": []
            }
            
            # 1. ç”Ÿæˆå°é¢æç¤ºè¯
            logger.info("ğŸ­ æ­¥éª¤1: ç”Ÿæˆå°é¢æç¤ºè¯...")
            cover_prompt = self._generate_cover_prompt(
                framework_content, 
                character_profiles, 
                system_prompt
            )
            if cover_prompt:
                all_prompts["å°é¢"] = cover_prompt
                logger.info("âœ… å°é¢æç¤ºè¯ç”Ÿæˆå®Œæˆ")
            else:
                logger.warning("âš ï¸ å°é¢æç¤ºè¯ç”Ÿæˆå¤±è´¥")
            
            # 2. æ‰¹é‡ç”Ÿæˆæ‰€æœ‰ç‰‡æ®µçš„æç¤ºè¯
            logger.info("ğŸ“š æ­¥éª¤2: æ‰¹é‡ç”Ÿæˆæ‰€æœ‰ç‰‡æ®µæç¤ºè¯...")
            segments_prompts = self._generate_all_segments_prompts(
                segments_info,
                character_profiles,
                system_prompt
            )
            
            if segments_prompts:
                all_prompts["ç‰‡æ®µ"] = segments_prompts
                logger.info(f"âœ… æˆåŠŸç”Ÿæˆ {len(segments_prompts)} ä¸ªç‰‡æ®µçš„æç¤ºè¯")
            
            # ä¿å­˜æ‰€æœ‰æç¤ºè¯åˆ°æ–‡ä»¶
            if all_prompts["å°é¢"] or all_prompts["ç‰‡æ®µ"]:
                output_file = self.final_dir / "sd_prompts.json"
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(all_prompts, f, ensure_ascii=False, indent=2)
                logger.info(f"ğŸ’¾ æ‰€æœ‰SDæç¤ºè¯å·²ä¿å­˜åˆ°: {output_file}")
                
                # åŒæ—¶ç”Ÿæˆä¸€ä¸ªæ˜“è¯»çš„markdownæ–‡ä»¶
                markdown_file = self.final_dir / "sd_prompts.md"
                with open(markdown_file, 'w', encoding='utf-8') as f:
                    f.write("# Stable Diffusion å›¾ç‰‡æç¤ºè¯\n\n")
                    f.write(f"ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                    f.write(f"ä½¿ç”¨Promptæ–‡ä»¶ï¼š{self.sd_prompt_file}\n\n")
                    f.write("---\n\n")
                    
                    # å°é¢éƒ¨åˆ†
                    if all_prompts["å°é¢"]:
                        f.write("## ğŸ­ å°é¢\n\n")
                        cover = all_prompts["å°é¢"]
                        f.write(f"**åœºæ™¯æ¦‚è¿°**: {cover.get('åœºæ™¯æ¦‚è¿°', '')}\n\n")
                        f.write(f"**æƒ…ç»ªç„¦ç‚¹**: {cover.get('æƒ…ç»ªç„¦ç‚¹', '')}\n\n")
                        if cover.get('æ–‡å­—å…ƒç´ '):
                            f.write(f"**æ–‡å­—å…ƒç´ **: {', '.join(cover.get('æ–‡å­—å…ƒç´ ', []))}\n\n")
                        f.write(f"### æç¤ºè¯\n```\n{cover.get('æç¤ºè¯', '')}\n```\n\n")
                        f.write("---\n\n")
                    
                    # ç‰‡æ®µéƒ¨åˆ†
                    f.write(f"## ğŸ“– æ•…äº‹ç‰‡æ®µï¼ˆå…±{len(all_prompts['ç‰‡æ®µ'])}ä¸ªï¼‰\n\n")
                    for prompt_info in all_prompts["ç‰‡æ®µ"]:
                        f.write(f"### ç‰‡æ®µ {prompt_info.get('ç‰‡æ®µ', '')}\n\n")
                        f.write(f"**åœºæ™¯æ¦‚è¿°**: {prompt_info.get('åœºæ™¯æ¦‚è¿°', '')}\n\n")
                        f.write(f"**æ ¸å¿ƒæƒ…ç»ª**: {prompt_info.get('æ ¸å¿ƒæƒ…ç»ª', '')}\n\n")
                        if prompt_info.get('æƒ…ç»ªç»†èŠ‚'):
                            f.write(f"**æƒ…ç»ªç»†èŠ‚**: {prompt_info.get('æƒ…ç»ªç»†èŠ‚', '')}\n\n")
                        f.write(f"#### æç¤ºè¯\n```\n{prompt_info.get('æç¤ºè¯', '')}\n```\n\n")
                        f.write("---\n\n")
                
                logger.info(f"ğŸ“ Markdownæ ¼å¼æç¤ºè¯å·²ä¿å­˜åˆ°: {markdown_file}")
                return True
            else:
                logger.warning("æ²¡æœ‰ç”Ÿæˆä»»ä½•æç¤ºè¯")
                return False
                
        except Exception as e:
            logger.error(f"ç”ŸæˆSDæç¤ºè¯å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _get_chapter_by_segment(self, segment_num: int) -> str:
        """æ ¹æ®ç‰‡æ®µç¼–å·è¿”å›æ‰€å±ç« èŠ‚
        
        Args:
            segment_num: ç‰‡æ®µç¼–å·
            
        Returns:
            ç« èŠ‚åç§°
        """
        if self.num_segments == 9:
            # 9ç‰‡æ®µå¯¹åº”9æ­¥ç»“æ„
            step_names = ['é’©å­å¼€åœº', 'è§’è‰²ä¸åŠ¨æœº', 'æ„å¤–è½¬æŠ˜', 'å°è¯•ä¸å¤±è´¥', 
                         'æƒ…ç»ªä½è°·', 'é¡¿æ‚Ÿä¸è½¬å˜', 'æœ€ç»ˆè¡ŒåŠ¨', 'èƒœåˆ©çš„ä»£ä»·', 'æ–°çš„æ‚¬å¿µ']
            if segment_num <= len(step_names):
                return step_names[segment_num - 1]
            return "æœªçŸ¥ç« èŠ‚"
        else:
            # 30ç‰‡æ®µçš„åŸå§‹é€»è¾‘
            if segment_num <= 4:
                return "Chapter One: Beginning"
            elif segment_num <= 13:
                return "Chapter Two: Development"
            elif segment_num <= 19:
                return "Chapter Three: Conflict Escalation"
            elif segment_num <= 26:
                return "Chapter Four: Climax"
            else:
                return "Chapter Five: Resolution"
    
    def _extract_characters_from_framework(self, framework_content: str) -> list:
        """ä»frameworkä¸­æå–è§’è‰²ä¿¡æ¯
        
        Args:
            framework_content: frameworkæ–‡ä»¶å†…å®¹
            
        Returns:
            è§’è‰²ä¿¡æ¯åˆ—è¡¨
        """
        import re
        
        characters = []
        
        # æŸ¥æ‰¾Character Visual Designéƒ¨åˆ†
        design_pattern = r"Character Visual Design\n=+\n(.*?)(?:\n=+|$)"
        design_match = re.search(design_pattern, framework_content, re.DOTALL)
        
        if not design_match:
            return characters
        
        design_section = design_match.group(1)
        
        # è§£ææ¯ä¸ªè§’è‰²
        # ä¸»è§’ - Jessica Martinez
        jessica_pattern = r"Protagonist.*?Jessica Martinez.*?SD Prompt: `([^`]+)`"
        jessica_match = re.search(jessica_pattern, design_section, re.DOTALL)
        if jessica_match:
            characters.append({
                "name": "Jessica Martinez",
                "role": "protagonist",
                "age": "Early 30s",
                "description": "Average height (5'6\"), slender build, long dark brown hair, deep-set brown eyes",
                "sd_prompt": jessica_match.group(1)
            })
        
        # Amber
        amber_pattern = r"Character 2.*?Amber.*?SD Prompt: `([^`]+)`"
        amber_match = re.search(amber_pattern, design_section, re.DOTALL)
        if amber_match:
            characters.append({
                "name": "Amber",
                "role": "antagonist",
                "age": "Late 20s",
                "description": "Tall (5'8\"), slender, sun-kissed blonde hair, influencer aesthetic",
                "sd_prompt": amber_match.group(1)
            })
        
        # Mom
        mom_pattern = r"Character 3.*?Mom.*?SD Prompt: `([^`]+)`"
        mom_match = re.search(mom_pattern, design_section, re.DOTALL)
        if mom_match:
            characters.append({
                "name": "Mom",
                "role": "secondary antagonist",
                "age": "Late 50s",
                "description": "Average height (5'5\"), dyed blonde hair, anxious eyes",
                "sd_prompt": mom_match.group(1)
            })
        
        # Nurse Clare
        clare_pattern = r"Character 4.*?Nurse Clare.*?SD Prompt: `([^`]+)`"
        clare_match = re.search(clare_pattern, design_section, re.DOTALL)
        if clare_match:
            characters.append({
                "name": "Nurse Clare",
                "role": "ally",
                "age": "Early 50s", 
                "description": "Sturdy build, salt-and-pepper hair, warm empathetic eyes",
                "sd_prompt": clare_match.group(1)
            })
        
        return characters
    
    def _extract_segments_from_framework(self, framework_content: str) -> dict:
        """ä»frameworkä¸­æå–ç‰‡æ®µä¿¡æ¯
        
        Args:
            framework_content: frameworkæ–‡ä»¶å†…å®¹
            
        Returns:
            ç‰‡æ®µä¿¡æ¯å­—å…¸ {segment_id: info}
        """
        import re
        
        segments = {}
        
        # æŸ¥æ‰¾Two-Level Story Frameworkéƒ¨åˆ†
        framework_pattern = r"Two-Level Story Framework.*?\n=+\n(.*?)(?:\n=+\nCharacter|$)"
        framework_match = re.search(framework_pattern, framework_content, re.DOTALL)
        
        if not framework_match:
            return segments
        
        story_section = framework_match.group(1)
        
        # åŒ¹é…æ¯ä¸ªç‰‡æ®µ
        segment_pattern = r"Segment (\d+):\s*([^\n]+?)(?:\s*\(\d+\s*words?\))?\n- Content:\s*([^\n]+)\n- Focus:\s*([^\n]+)\n- Connection:\s*([^\n]+)"
        
        for match in re.finditer(segment_pattern, story_section):
            segment_id = match.group(1)  # ä¿æŒä¸ºå­—ç¬¦ä¸²
            segments[segment_id] = {
                'title': match.group(2).strip(),
                'content': match.group(3).strip(),
                'focus': match.group(4).strip(),
                'connection': match.group(5).strip()
            }
        
        return segments
    
    def _generate_cover_prompt(self, framework_content: str, character_profiles: list, system_prompt: str) -> dict:
        """ç”Ÿæˆå°é¢çš„SDæç¤ºè¯
        
        Args:
            framework_content: frameworkæ–‡ä»¶å†…å®¹
            character_profiles: è§’è‰²ä¿¡æ¯åˆ—è¡¨
            system_prompt: SDç”Ÿæˆçš„ç³»ç»Ÿæç¤ºè¯
            
        Returns:
            å°é¢æç¤ºè¯å­—å…¸
        """
        import re
        
        try:
            # æå–Thumbnail Designä¿¡æ¯
            thumbnail_info = {}
            thumbnail_pattern = r"### Thumbnail Design\n(.*?)(?:\n###|\n==|\Z)"
            thumbnail_match = re.search(thumbnail_pattern, framework_content, re.DOTALL)
            
            if thumbnail_match:
                thumbnail_text = thumbnail_match.group(1)
                
                # æå–Visual Elements
                visual_pattern = r"Visual Elements:\s*([^\n]+(?:\n[^\n]+)*?)(?:\nText Overlay:|$)"
                visual_match = re.search(visual_pattern, thumbnail_text)
                if visual_match:
                    thumbnail_info['visual_elements'] = visual_match.group(1).strip()
                
                # æå–Text Overlay
                text_pattern = r"Text Overlay:\s*([^\n]+(?:\n[^\n]+)*?)(?:\nEmotional Impact:|$)"
                text_match = re.search(text_pattern, thumbnail_text)
                if text_match:
                    thumbnail_info['text_overlay'] = text_match.group(1).strip()
                
                # æå–Emotional Impact
                emotion_pattern = r"Emotional Impact:\s*([^\n]+)"
                emotion_match = re.search(emotion_pattern, thumbnail_text)
                if emotion_match:
                    thumbnail_info['emotional_impact'] = emotion_match.group(1).strip()
            
            # æå–æ ‡é¢˜é€‰é¡¹
            titles = []
            title_pattern = r"### Title Options\n(.*?)(?:\n###|\n==|\Z)"
            title_match = re.search(title_pattern, framework_content, re.DOTALL)
            if title_match:
                title_text = title_match.group(1)
                title_lines = [line.strip() for line in title_text.split('\n') if line.strip() and line.strip()[0].isdigit()]
                titles = [re.sub(r'^\d+\.\s*', '', line) for line in title_lines]
            
            # æ„å»ºå°é¢ç”Ÿæˆçš„è¾“å…¥
            cover_input = json.dumps({
                "task_type": "cover",
                "framework_info": {
                    "thumbnail_design": thumbnail_info,
                    "title_options": titles,
                    "core_conflict": "Family abandonment during surgery vs. luxury vacation"
                },
                "character_profiles": character_profiles
            }, ensure_ascii=False, indent=2)
            
            # DEBUG: è®°å½•å®Œæ•´è¾“å…¥
            logger.debug("=" * 80)
            logger.debug("[DEBUG] _generate_cover_prompt - AIè°ƒç”¨è¾“å…¥:")
            logger.debug(f"system_prompté•¿åº¦: {len(system_prompt)} å­—ç¬¦")
            logger.debug("å®Œæ•´system_prompt:")
            logger.debug(system_prompt)
            logger.debug("å®Œæ•´cover_input:")
            logger.debug(cover_input)
            logger.debug("=" * 80)
            
            # è°ƒç”¨AIç”Ÿæˆå°é¢æç¤ºè¯
            response = self.gemini_client.analyze_text(
                text=cover_input,
                prompt=system_prompt
            )
            
            # DEBUG: è®°å½•å®Œæ•´è¾“å‡º
            logger.debug("=" * 80)
            logger.debug("[DEBUG] _generate_cover_prompt - AIè°ƒç”¨è¾“å‡º:")
            logger.debug(f"è¾“å‡ºé•¿åº¦: {len(response) if response else 0} å­—ç¬¦")
            if response:
                logger.debug("å®Œæ•´è¾“å‡º:")
                logger.debug(response)
            else:
                logger.debug("å“åº”ä¸ºç©º")
            logger.debug("=" * 80)
            
            if response:
                # è§£æJSONå“åº”
                json_match = re.search(r'```json\s*\n(.+?)\n```', response, re.DOTALL)
                if json_match:
                    cover_data = json.loads(json_match.group(1))
                    return cover_data
            
            return None
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå°é¢æç¤ºè¯å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _extract_opening_hook_from_framework(self, framework_content: str) -> str:
        """ä»frameworkä¸­æå–Opening Hookä½œä¸ºSegment 1
        
        Args:
            framework_content: frameworkæ–‡ä»¶å†…å®¹
            
        Returns:
            å¼€åœºé’©å­çš„æ–‡æœ¬å†…å®¹
        """
        import re
        
        # æŸ¥æ‰¾Opening Hookéƒ¨åˆ†çš„Narration
        hook_pattern = r"### Opening Hook.*?Narration:\n(.*?)(?:\n\nSubtitles:|$)"
        hook_match = re.search(hook_pattern, framework_content, re.DOTALL)
        
        if hook_match:
            narration = hook_match.group(1).strip()
            # æ¸…ç†å¼•å·å’Œæ ¼å¼
            narration = narration.replace('"', '').replace('\n', ' ')
            # åˆ†æ®µå¤„ç†ï¼Œè®©æ–‡æœ¬æ›´æœ‰èŠ‚å¥æ„Ÿ
            sentences = narration.split('.')
            formatted_text = []
            
            for sentence in sentences:
                sentence = sentence.strip()
                if sentence:
                    # æ¢å¤å¥å·
                    formatted_text.append(sentence + '.')
            
            # å°†å¥å­ç»„åˆæˆæ®µè½
            # ç¬¬ä¸€æ®µï¼šå¼€åœºç™½
            opening = formatted_text[0] if formatted_text else ""
            
            # ç»„åˆæˆæœ€ç»ˆçš„å¼€åœºé’©å­
            result = opening
            if len(formatted_text) > 1:
                result += "\n\n" + " ".join(formatted_text[1:3]) if len(formatted_text) > 2 else formatted_text[1]
            if len(formatted_text) > 3:
                result += "\n\n" + " ".join(formatted_text[3:])
            
            return result
        
        # å¦‚æœæ‰¾ä¸åˆ°Opening Hookï¼Œå°è¯•ä»Segment 1çš„Contentä¸­æå–
        segment1_pattern = r"Segment 1:.*?\n- Content:\s*([^\n]+)"
        segment1_match = re.search(segment1_pattern, framework_content)
        
        if segment1_match:
            content = segment1_match.group(1).strip()
            # æ ¼å¼åŒ–å†…å®¹
            return content.replace('A flash-forward scene:', '').strip()
        
        # é»˜è®¤è¿”å›
        return "They say blood is thicker than water. I say, sometimes, it's just a stain you need to scrub away."
    
    def _generate_all_segments_prompts(self, segments_info: dict, character_profiles: list, system_prompt: str) -> list:
        """æ‰¹é‡ç”Ÿæˆæ‰€æœ‰ç‰‡æ®µçš„SDæç¤ºè¯ï¼ˆä¸€æ¬¡APIè°ƒç”¨ï¼‰
        
        Args:
            segments_info: ç‰‡æ®µä¿¡æ¯å­—å…¸ {segment_id: info}
            character_profiles: è§’è‰²ä¿¡æ¯åˆ—è¡¨
            system_prompt: SDç”Ÿæˆçš„ç³»ç»Ÿæç¤ºè¯
            
        Returns:
            åŒ…å«æ‰€æœ‰ç‰‡æ®µæç¤ºè¯çš„åˆ—è¡¨
        """
        import re
        
        try:
            logger.info("å¼€å§‹æ‰¹é‡ç”Ÿæˆæ‰€æœ‰ç‰‡æ®µçš„SDæç¤ºè¯...")
            
            # æ„å»ºæ‰¹é‡è¾“å…¥æ•°æ®
            all_segments_data = []
            
            # å°†segments_infoæŒ‰ç…§ç¼–å·æ’åº
            sorted_segments = sorted(segments_info.items(), key=lambda x: int(x[0]))
            
            for segment_id, segment_info in sorted_segments:
                segment_num = int(segment_id)
                
                # è¯»å–å¯¹åº”çš„ç‰‡æ®µæ–‡ä»¶å†…å®¹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                segment_file = self.segments_dir / f"segment_{segment_id.zfill(2)}.txt"
                segment_content = ""
                if segment_file.exists():
                    with open(segment_file, 'r', encoding='utf-8') as f:
                        segment_content = f.read()[:500]  # åªå–å‰500å­—ä½œä¸ºå‚è€ƒ
                
                # æ„å»ºå•ä¸ªç‰‡æ®µçš„è¾“å…¥æ•°æ®
                segment_data = {
                    "segment_id": segment_id,
                    "segment_number": segment_num,
                    "chapter": self._get_chapter_by_segment(segment_num),
                    "content_preview": segment_content or segment_info.get('content', ''),
                    "focus": segment_info.get('focus', ''),
                    "connection": segment_info.get('connection', ''),
                    "key_elements": segment_info.get('key_elements', [])
                }
                
                # ç‰¹æ®Šåœºæ™¯æ ‡è®°
                if self.num_segments == 9:
                    # 9ç‰‡æ®µçš„åœºæ™¯ç±»å‹
                    scene_types = {
                        1: "opening_hook",        # é’©å­å¼€åœº
                        3: "major_turning_point", # æ„å¤–è½¬æŠ˜
                        5: "lowest_point",        # æƒ…ç»ªä½è°·
                        7: "climax",             # æœ€ç»ˆè¡ŒåŠ¨
                        9: "epilogue"            # æ–°çš„æ‚¬å¿µ
                    }
                    segment_data["scene_type"] = scene_types.get(segment_num, "regular")
                else:
                    # 30ç‰‡æ®µçš„åŸå§‹æ ‡è®°é€»è¾‘
                    if segment_num == 1:
                        segment_data["scene_type"] = "opening_hook"
                    elif segment_num in [5, 14, 20]:  # å…³é”®è½¬æŠ˜ç‚¹
                        segment_data["scene_type"] = "major_turning_point"
                    elif segment_num in [18]:  # æœ€ä½ç‚¹
                        segment_data["scene_type"] = "lowest_point"
                    elif segment_num in [24, 25, 26]:  # é«˜æ½®
                        segment_data["scene_type"] = "climax"
                    elif segment_num == 30:
                        segment_data["scene_type"] = "epilogue"
                    else:
                        segment_data["scene_type"] = "regular"
                
                all_segments_data.append(segment_data)
            
            # æ„å»ºæ‰¹é‡è¯·æ±‚çš„è¾“å…¥
            batch_input = json.dumps({
                "task_type": "batch_segments",
                "total_segments": len(all_segments_data),
                "segments_data": all_segments_data,
                "character_profiles": character_profiles,
                "story_theme": "Family betrayal and personal growth"
            }, ensure_ascii=False, indent=2)
            
            # ä¿®æ”¹ç³»ç»Ÿæç¤ºè¯ï¼Œè¦æ±‚æ‰¹é‡è¿”å›
            batch_prompt = f"""
{system_prompt}

ç‰¹åˆ«è¦æ±‚ï¼š
1. è¯·ä¸€æ¬¡æ€§ç”Ÿæˆæ‰€æœ‰{len(all_segments_data)}ä¸ªç‰‡æ®µçš„SDæç¤ºè¯
2. è¿”å›ä¸€ä¸ªJSONæ•°ç»„ï¼ŒåŒ…å«æ‰€æœ‰ç‰‡æ®µçš„æç¤ºè¯
3. æ¯ä¸ªç‰‡æ®µéƒ½è¦åŒ…å«: ç‰‡æ®µç¼–å·ã€åœºæ™¯æ¦‚è¿°ã€æ ¸å¿ƒæƒ…ç»ªã€æç¤ºè¯
4. ä¿æŒè§’è‰²å¤–è§‚çš„ä¸€è‡´æ€§
5. æ ¹æ®ä¸åŒçš„scene_typeè°ƒæ•´ç”»é¢æ°›å›´ï¼š
   - opening_hook: ç¥ç§˜ã€å¼•äººå…¥èƒœ
   - major_turning_point: æˆå‰§æ€§ã€å†²çªæ„Ÿ
   - lowest_point: é»‘æš—ã€ç»æœ›
   - climax: æ¿€çƒˆã€é«˜èƒ½
   - epilogue: å¹³é™ã€å›å‘³
   - regular: æ ¹æ®å†…å®¹è°ƒæ•´

è¯·è¿”å›å¦‚ä¸‹æ ¼å¼çš„JSONï¼š
```json
[
  {{
    "ç‰‡æ®µ": "01",
    "åœºæ™¯æ¦‚è¿°": "...",
    "æ ¸å¿ƒæƒ…ç»ª": "...",
    "æç¤ºè¯": "..."
  }},
  ...
]
```
"""
            
            # æ„å»ºå®Œæ•´æç¤º
            full_batch_prompt = batch_prompt + "\n\nè¾“å…¥æ•°æ®ï¼š\n" + batch_input
            
            # DEBUG: è®°å½•å®Œæ•´è¾“å…¥
            logger.debug("=" * 80)
            logger.debug("[DEBUG] _generate_all_segments_prompts - AIè°ƒç”¨è¾“å…¥:")
            logger.debug(f"è¾“å…¥æ€»é•¿åº¦: {len(full_batch_prompt)} å­—ç¬¦")
            logger.debug(f"ç‰‡æ®µæ•°é‡: {len(all_segments_data)}")
            logger.debug("å®Œæ•´è¾“å…¥å†…å®¹:")
            logger.debug(full_batch_prompt)
            logger.debug("=" * 80)
            
            # è°ƒç”¨AIç”Ÿæˆæ‰€æœ‰æç¤ºè¯
            response = self.gemini_client.generate_content(full_batch_prompt)
            
            # DEBUG: è®°å½•å®Œæ•´è¾“å‡º
            logger.debug("=" * 80)
            logger.debug("[DEBUG] _generate_all_segments_prompts - AIè°ƒç”¨è¾“å‡º:")
            logger.debug(f"è¾“å‡ºé•¿åº¦: {len(response) if response else 0} å­—ç¬¦")
            if response:
                logger.debug("å®Œæ•´è¾“å‡ºå†…å®¹:")
                logger.debug(response)
            else:
                logger.debug("å“åº”ä¸ºç©º")
            logger.debug("=" * 80)
            
            if response:
                # è§£æJSONå“åº”
                json_match = re.search(r'```json\s*\n(.+?)\n```', response, re.DOTALL)
                if json_match:
                    segments_prompts = json.loads(json_match.group(1))
                    
                    # éªŒè¯è¿”å›çš„æ•°é‡
                    if isinstance(segments_prompts, list):
                        logger.info(f"âœ… æˆåŠŸæ‰¹é‡ç”Ÿæˆ {len(segments_prompts)} ä¸ªç‰‡æ®µçš„SDæç¤ºè¯")
                        return segments_prompts
                    else:
                        logger.warning("è¿”å›æ ¼å¼ä¸æ˜¯æ•°ç»„ï¼Œå°è¯•è§£æ")
                        # å¦‚æœä¸æ˜¯æ•°ç»„ï¼Œå¯èƒ½æ˜¯å•ä¸ªå¯¹è±¡ï¼Œè½¬æ¢ä¸ºæ•°ç»„
                        return [segments_prompts] if segments_prompts else []
                else:
                    logger.warning("æ— æ³•ä»å“åº”ä¸­æå–JSON")
                    # å°è¯•ç›´æ¥è§£æå“åº”
                    try:
                        segments_prompts = json.loads(response)
                        if isinstance(segments_prompts, list):
                            return segments_prompts
                    except Exception as e:
                        logger.debug(f"ç›´æ¥è§£æå“åº”å¤±è´¥: {e}")
                        import traceback
                        traceback.print_exc()
                        pass
            
            logger.warning("æ‰¹é‡ç”Ÿæˆå¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨")
            return []
            
        except Exception as e:
            logger.error(f"æ‰¹é‡ç”Ÿæˆç‰‡æ®µæç¤ºè¯å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def run(self):
        """æ‰§è¡Œå®Œæ•´çš„æ•…äº‹åˆ›ä½œæµç¨‹"""
        logger.info("ğŸš€ å¼€å§‹æ‰§è¡ŒYouTubeæ•…äº‹åˆ›ä½œæµç¨‹ V2")
        start_time = time.time()
        
        try:
            # è·å–YouTubeæ•°æ®
            youtube_data = self.fetch_youtube_data()
            if not youtube_data:
                logger.error("âŒ æ— æ³•è·å–YouTubeæ•°æ®ï¼Œæµç¨‹ç»ˆæ­¢")
                return False
            
            # ç¬¬ä¸€é˜¶æ®µï¼šæå–æ•…äº‹DNA
            story_dna, text_analysis = self.phase1_extract_dna(
                youtube_data.get('subtitles', '')
            )
            if not story_dna:
                logger.error("âŒ æ•…äº‹DNAæå–å¤±è´¥ï¼Œæµç¨‹ç»ˆæ­¢")
                return False
            
            # ç¬¬äºŒé˜¶æ®µï¼šç”Ÿæˆæ¡†æ¶
            framework = self.phase2_generate_framework(
                story_dna,
                youtube_data['video_info'],
                youtube_data.get('comments', [])
            )
            if not framework:
                logger.error("âŒ æ¡†æ¶ç”Ÿæˆå¤±è´¥ï¼Œæµç¨‹ç»ˆæ­¢")
                return False
            
            # ç¬¬ä¸‰é˜¶æ®µï¼šåˆ†æ®µç”Ÿæˆï¼ˆä½¿ç”¨ç®€åŒ–ç‰ˆï¼‰
            segments = self.phase3_generate_segments_simple(story_dna, framework)
            if not segments:
                logger.error("âŒ ç‰‡æ®µç”Ÿæˆå¤±è´¥ï¼Œæµç¨‹ç»ˆæ­¢")
                return False
            
            # ç¬¬å››é˜¶æ®µï¼šæ‹¼æ¥
            draft = self.phase4_concat_segments(segments)
            
            # ç¬¬äº”é˜¶æ®µï¼šæ¶¦è‰²
            final_story = self.phase5_polish(framework, draft)
            
            # ç”ŸæˆæŠ¥å‘Š
            self.generate_final_report()
            
            # å·²ç§»é™¤ç”Ÿå›¾éƒ¨åˆ†ï¼Œå¦‚éœ€ç”Ÿæˆå›¾ç‰‡æç¤ºè¯è¯·å•ç‹¬è¿è¡Œ generate_image_prompts.py
            logger.info("âœ… æ•…äº‹ç”Ÿæˆå®Œæˆï¼å¦‚éœ€ç”Ÿæˆå›¾ç‰‡æç¤ºè¯ï¼Œè¯·è¿è¡Œï¼š")
            logger.info(f"   python generate_image_prompts.py --creator {self.creator_name} --video {self.video_id} --generator_type jimeng")
            
            # è®¡ç®—æ€»è€—æ—¶
            elapsed_time = time.time() - start_time
            logger.info(f"âœ… æµç¨‹å®Œæˆï¼æ€»è€—æ—¶: {elapsed_time/60:.1f}åˆ†é’Ÿ")
            logger.info(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {self.output_dir}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ æµç¨‹æ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='YouTube Story Creator V2')
    parser.add_argument('video_id', help='YouTubeè§†é¢‘ID')
    parser.add_argument('creator_name', help='åˆ›ä½œè€…åç§°')
    parser.add_argument('--length', type=int, default=30000, help='ç›®æ ‡æ•…äº‹é•¿åº¦ï¼ˆé»˜è®¤30000å­—ï¼‰')
    parser.add_argument('--segments', type=int, default=9, help='ç‰‡æ®µæ•°é‡ï¼ˆé»˜è®¤9ä¸ªï¼Œå¯¹åº”9æ­¥ç»“æ„ï¼‰')
    
    args = parser.parse_args()
    
    # åˆ›å»ºå¹¶è¿è¡Œ
    creator = YouTubeStoryCreatorV2(
        video_id=args.video_id,
        creator_name=args.creator_name,
        target_length=args.length,
        num_segments=args.segments
    )
    
    success = creator.run()
    
    if success:
        print("\nâœ¨ æ•…äº‹åˆ›ä½œå®Œæˆï¼")
    else:
        print("\nâŒ æ•…äº‹åˆ›ä½œå¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—")
        sys.exit(1)


if __name__ == "__main__":
    main()