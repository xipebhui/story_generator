#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç‹¬ç«‹è¿è¡ŒYouTubeå…ƒæ•°æ®ç”Ÿæˆ
ç”¨äºä¸ºå·²ç»ç”Ÿæˆçš„æ•…äº‹è¡¥å……YouTubeå…ƒæ•°æ®
"""

import sys
import json
import logging
from pathlib import Path
import argparse

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from pipeline_context_v3 import PipelineContextV3
from pipeline_steps_youtube_metadata import GenerateYouTubeMetadataStep
from gemini_client import GeminiClient

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


def generate_youtube_metadata(video_id: str, creator_name: str = "test"):
    """
    ä¸ºå·²æœ‰çš„æ•…äº‹ç”ŸæˆYouTubeå…ƒæ•°æ®
    
    Args:
        video_id: è§†é¢‘ID
        creator_name: åˆ›ä½œè€…åç§°
    """
    
    logger.info(f"ğŸ¬ ä¸ºè§†é¢‘ {video_id} ç”ŸæˆYouTubeå…ƒæ•°æ®")
    
    # åˆ›å»ºä¸Šä¸‹æ–‡
    context = PipelineContextV3(
        video_id=video_id,
        creator_name=creator_name,
        cache_dir=Path("story_result") / creator_name / video_id
    )
    
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not context.cache_dir.exists():
        logger.error(f"âŒ ç›®å½•ä¸å­˜åœ¨: {context.cache_dir}")
        return False
    
    # åŠ è½½å·²æœ‰æ•°æ®
    try:
        # 1. åŠ è½½framework
        framework_file = context.cache_dir / "processing" / "framework_v3.json"
        if framework_file.exists():
            with open(framework_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                context.framework_v3_json = data.get('json', {})
                logger.info(f"âœ… åŠ è½½frameworkæˆåŠŸ")
        else:
            logger.error(f"âŒ Frameworkæ–‡ä»¶ä¸å­˜åœ¨: {framework_file}")
            return False
        
        # 2. åŠ è½½æœ€ç»ˆæ•…äº‹
        story_file = context.cache_dir / "final" / "story.txt"
        if story_file.exists():
            with open(story_file, 'r', encoding='utf-8') as f:
                context.final_story = f.read()
                logger.info(f"âœ… åŠ è½½æ•…äº‹æˆåŠŸï¼Œé•¿åº¦: {len(context.final_story)} å­—ç¬¦")
        else:
            logger.warning(f"âš ï¸ æ•…äº‹æ–‡ä»¶ä¸å­˜åœ¨: {story_file}")
        
        # 3. åŠ è½½è§†é¢‘ä¿¡æ¯
        video_info_file = context.cache_dir / "raw" / "video_info.json"
        if video_info_file.exists():
            with open(video_info_file, 'r', encoding='utf-8') as f:
                context.video_info = json.load(f)
                logger.info(f"âœ… åŠ è½½è§†é¢‘ä¿¡æ¯: {context.video_info.get('title', 'N/A')}")
        
        # 4. åŠ è½½segmentä¿¡æ¯
        parsed_file = context.cache_dir / "processing" / "parsed_segments.json"
        if parsed_file.exists():
            with open(parsed_file, 'r', encoding='utf-8') as f:
                parsed_data = json.load(f)
                context.segment_count = parsed_data.get('segment_count', 0)
                context.segment_tasks = parsed_data.get('segment_tasks', [])
                logger.info(f"âœ… Segmentæ•°é‡: {context.segment_count}")
        
    except Exception as e:
        logger.error(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # åˆ›å»ºGeminiå®¢æˆ·ç«¯
    api_key = "sk-oFdSWMX8z3cAYYCrGYCcwAupxMdiErcOKBsfi5k0QdRxELCu"
    gemini_client = GeminiClient(api_key=api_key)
    
    # åˆ›å»ºå¹¶æ‰§è¡Œæ­¥éª¤
    logger.info("ğŸ¤– å¼€å§‹ç”ŸæˆYouTubeå…ƒæ•°æ®...")
    step = GenerateYouTubeMetadataStep(gemini_client)
    result = step.execute(context)
    
    if result.success:
        logger.info("âœ… YouTubeå…ƒæ•°æ®ç”ŸæˆæˆåŠŸ")
        
        # éªŒè¯æ–‡ä»¶
        metadata_json = context.cache_dir / "final" / "youtube_metadata.json"
        metadata_md = context.cache_dir / "final" / "youtube_metadata.md"
        
        if metadata_json.exists():
            logger.info(f"ğŸ“ JSONæ–‡ä»¶: {metadata_json}")
            
            # æ˜¾ç¤ºéƒ¨åˆ†å†…å®¹
            with open(metadata_json, 'r', encoding='utf-8') as f:
                data = json.load(f)
                print("\n" + "="*60)
                print("ç”Ÿæˆçš„æ ‡é¢˜å»ºè®®:")
                print("="*60)
                
                # ä¸­æ–‡æ ‡é¢˜
                if 'titles' in data and 'chinese' in data['titles']:
                    print("\nä¸­æ–‡æ ‡é¢˜:")
                    for i, title in enumerate(data['titles']['chinese'], 1):
                        print(f"  {i}. {title}")
                
                # è‹±æ–‡æ ‡é¢˜
                if 'titles' in data and 'english' in data['titles']:
                    print("\nè‹±æ–‡æ ‡é¢˜:")
                    for i, title in enumerate(data['titles']['english'], 1):
                        print(f"  {i}. {title}")
        
        if metadata_md.exists():
            logger.info(f"ğŸ“ Markdownæ–‡ä»¶: {metadata_md}")
            print("\n" + "="*60)
            print(f"å®Œæ•´çš„YouTubeå‘å¸ƒå»ºè®®å·²ä¿å­˜åˆ°:")
            print(f"  {metadata_md}")
            print("="*60)
        
        return True
    else:
        logger.error("âŒ YouTubeå…ƒæ•°æ®ç”Ÿæˆå¤±è´¥")
        return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='ä¸ºå·²ç”Ÿæˆçš„æ•…äº‹æ·»åŠ YouTubeå…ƒæ•°æ®',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python generate_youtube_metadata_standalone.py aSiVP7rJsqQ
  python generate_youtube_metadata_standalone.py VIDEO_ID --creator myname
        """
    )
    
    parser.add_argument('video_id', help='YouTubeè§†é¢‘ID')
    parser.add_argument('--creator', default='test', help='åˆ›ä½œè€…åç§°ï¼ˆé»˜è®¤: testï¼‰')
    
    args = parser.parse_args()
    
    # æ‰§è¡Œç”Ÿæˆ
    success = generate_youtube_metadata(args.video_id, args.creator)
    
    if success:
        print("\nâœ… YouTubeå…ƒæ•°æ®ç”Ÿæˆå®Œæˆ!")
    else:
        print("\nâŒ ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()