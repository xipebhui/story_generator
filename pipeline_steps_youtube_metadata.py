#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
YouTube Metadata Generation Step
ç”ŸæˆåŒè¯­ç‰ˆæœ¬çš„YouTubeå‘å¸ƒå»ºè®®
"""

import json
import logging
import os
from typing import Dict, Any
from pathlib import Path

from pipeline_architecture import PipelineStep, StepResult
from pipeline_context_v3 import PipelineContextV3
from gemini_client import GeminiClient

logger = logging.getLogger(__name__)


class GenerateYouTubeMetadataStep(PipelineStep):
    """ç”ŸæˆYouTubeå‘å¸ƒå…ƒæ•°æ®ï¼ˆåŒè¯­ç‰ˆæœ¬ï¼‰"""
    
    def __init__(self, gemini_client: GeminiClient):
        super().__init__("generate_youtube_metadata")
        self.gemini_client = gemini_client
    
    def execute(self, context: PipelineContextV3) -> StepResult:
        """ç”ŸæˆYouTubeå…ƒæ•°æ®"""
        try:
            logger.info("ğŸ¬ ç”ŸæˆYouTubeå‘å¸ƒå»ºè®®...")
            
            # æ£€æŸ¥ç¼“å­˜
            if context.cache_dir:
                cached_metadata = self._load_cached_metadata(context)
                if cached_metadata:
                    context.youtube_metadata = cached_metadata
                    logger.info("âœ… ä»ç¼“å­˜åŠ è½½YouTubeå…ƒæ•°æ®")
                    return StepResult(success=True, data=cached_metadata)
            
            # å‡†å¤‡è¾“å…¥æ•°æ®
            input_data = self._prepare_input(context)
            
            # ç”Ÿæˆå…ƒæ•°æ®
            metadata = self._generate_metadata(input_data)
            
            if metadata:
                context.youtube_metadata = metadata
                
                # ä¿å­˜ç»“æœ
                if context.save_intermediate and context.cache_dir:
                    self._save_metadata(context, metadata)
                
                logger.info("âœ… YouTubeå…ƒæ•°æ®ç”ŸæˆæˆåŠŸ")
                return StepResult(success=True, data=metadata)
            else:
                logger.warning("âš ï¸ YouTubeå…ƒæ•°æ®ç”Ÿæˆå¤±è´¥")
                return StepResult(success=True)  # ä¸å½±å“ä¸»æµç¨‹
                
        except json.JSONDecodeError as je:
            logger.warning(f"YouTube metadata JSON parsing failed: {je}")
            logger.debug(f"Error details - msg: {je.msg}, pos: {je.pos}, doc: {je.doc[:100] if je.doc else 'None'}")
            return StepResult(success=True)  # éå…³é”®æ­¥éª¤ï¼Œç»§ç»­æ‰§è¡Œ
        except Exception as e:
            logger.warning(f"YouTube metadata generation failed: {e}")
            logger.debug(f"Error type: {type(e).__name__}")
            import traceback
            logger.debug(f"Traceback: {traceback.format_exc()}")
            return StepResult(success=True)  # éå…³é”®æ­¥éª¤ï¼Œç»§ç»­æ‰§è¡Œ
    
    def _prepare_input(self, context: PipelineContextV3) -> Dict:
        """å‡†å¤‡è¾“å…¥æ•°æ®"""
        # ä»frameworkä¸­æå–å…³é”®ä¿¡æ¯
        framework_data = context.framework_v3_json
        
        # æå–æ•…äº‹ä¿¡æ¯
        story_info = {
            'title': framework_data.get('adaptationAnalysis', {}).get('newStoryTitle', ''),
            'core_concept': framework_data.get('adaptationAnalysis', {}).get('coreConcept', ''),
            'characters': framework_data.get('adaptationAnalysis', {}).get('mainCharacters', []),
            'hook': framework_data.get('adaptationAnalysis', {}).get('openingReplicationStrategy', {})
        }
        
        # æå–å‰1000å­—ç”¨äºåˆ†æ
        story_excerpt = context.final_story[:1000] if context.final_story else ""
        
        return {
            'video_info': context.video_info,
            'story_info': story_info,
            'story_excerpt': story_excerpt,
            'segment_count': context.segment_count
        }
    
    def _generate_metadata(self, input_data: Dict) -> Dict:


        meta_prompt_file = "prompts/youtube_meta_gen.md"

        with open(meta_prompt_file, "r", encoding="utf-8") as f:
           prompt_content = f.read()

        prompt = prompt_content + json.dumps(input_data, ensure_ascii=False, indent=4)

        
        try:
            response = self.gemini_client.generate_content(prompt)
            
            if response:
                # è§£æJSONå“åº”
                import re
                
                # å…ˆå°è¯•æå–markdownä»£ç å—ä¸­çš„JSON
                json_match = re.search(r'```json\s*\n(.*?)\n```', response, re.DOTALL)
                if json_match:
                    try:
                        metadata = json.loads(json_match.group(1))
                        return metadata
                    except json.JSONDecodeError as je:
                        logger.warning(f"Failed to parse JSON from code block: {je}")
                        logger.debug(f"JSON content that failed: {json_match.group(1)[:200]}...")
                
                # å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œå°è¯•ç›´æ¥è§£ææ•´ä¸ªå“åº”
                try:
                    # æ¸…ç†å“åº”ï¼Œå»é™¤å¯èƒ½çš„å‰åç©ºç™½å’ŒéJSONå†…å®¹
                    cleaned_response = response.strip()
                    
                    # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘å¼€å¤´çš„å¤§æ‹¬å·
                    if not cleaned_response.startswith('{') and '"titles"' in cleaned_response[:50]:
                        # å°è¯•ä¿®å¤ç¼ºå°‘å¼€å¤´å¤§æ‹¬å·çš„æƒ…å†µ
                        cleaned_response = '{' + cleaned_response
                        logger.debug("Added missing opening brace to JSON response")
                    
                    # å°è¯•æ‰¾åˆ°JSONçš„å¼€å§‹å’Œç»“æŸ
                    if cleaned_response.startswith('{'):
                        # æ‰¾åˆ°æœ€åä¸€ä¸ªåŒ¹é…çš„}
                        brace_count = 0
                        json_end = -1
                        for i, char in enumerate(cleaned_response):
                            if char == '{':
                                brace_count += 1
                            elif char == '}':
                                brace_count -= 1
                                if brace_count == 0:
                                    json_end = i + 1
                                    break
                        
                        if json_end > 0:
                            json_str = cleaned_response[:json_end]
                            metadata = json.loads(json_str)
                            return metadata
                        elif json_end == -1 and brace_count > 0:
                            # ç¼ºå°‘ç»“æŸæ‹¬å·ï¼Œå°è¯•æ·»åŠ 
                            cleaned_response += '}' * brace_count
                            logger.debug(f"Added {brace_count} missing closing braces")
                            metadata = json.loads(cleaned_response)
                            return metadata
                    
                    # æœ€åå°è¯•ç›´æ¥è§£æ
                    metadata = json.loads(cleaned_response)
                    return metadata
                    
                except json.JSONDecodeError as je:
                    logger.error(f"Failed to parse YouTube metadata JSON: {je}")
                    logger.debug(f"Response preview: {response[:500]}...")
            else:
                logger.error("No response from AI")
            
        except Exception as e:
            logger.error(f"AI generation failed: {e}")

    
    def _load_cached_metadata(self, context: PipelineContextV3) -> Dict:
        """åŠ è½½ç¼“å­˜çš„å…ƒæ•°æ®"""
        try:
            cache_file = context.cache_dir / "final" / "youtube_metadata.json"
            if cache_file.exists():
                with open(cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            logger.warning(f"Failed to load cached metadata: {e}")
        return None
    
    def _save_metadata(self, context: PipelineContextV3, metadata: Dict):
        """ä¿å­˜å…ƒæ•°æ®"""
        try:
            final_dir = context.cache_dir / "final"
            final_dir.mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜JSONæ ¼å¼
            json_file = final_dir / "youtube_metadata.json"
            logger.debug(f"ä¿å­˜YouTubeå…ƒæ•°æ®åˆ°: {json_file}")
            
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ğŸ’¾ YouTubeå…ƒæ•°æ®å·²ä¿å­˜: {json_file}")
            
        except Exception as e:
            logger.error(f"Failed to save YouTube metadata: {e}")
            logger.exception("è¯¦ç»†é”™è¯¯:")
